{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "digiteer.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n9_cTveKmse",
        "cellView": "both",
        "trusted": true
      },
      "source": [
        "import random as rd\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#submit = True\n",
        "submit = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZlvdpyYKx7V",
        "cellView": "both",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da79801b-d094-4991-9fbc-91432e88c420"
      },
      "source": [
        "# load the public MNIST dataset.\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train_norm = x_train/255.\n",
        "x_test_norm = x_test/255."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aGtML-Okikx",
        "trusted": true
      },
      "source": [
        "#kaggle = pd.read_csv('../input/digit-recognizer/test.csv')\n",
        "kaggle = pd.read_csv('https://github.com/davidabelin/kaggle-files/raw/main/digit-recognizer/test.csv')\n",
        "kaggle_norm = np.asarray(kaggle/255.)\n",
        "\n",
        "k_train = pd.read_csv('https://github.com/davidabelin/kaggle-files/raw/main/digit-recognizer/train.csv')\n",
        "k_labels = np.asarray(k_train['label'])\n",
        "k_train = k_train.drop(columns=['label'])\n",
        "k_train_norm = np.asarray(k_train/255.)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CYqd8LMZ75Z",
        "trusted": true
      },
      "source": [
        "# Add a channels dimension\n",
        "k_train_norm = k_train_norm.reshape(42000, 28, 28, 1)\n",
        "kaggle_norm = kaggle_norm.reshape(28000, 28, 28, 1)\n",
        "x_train_norm = x_train_norm.reshape(60000, 28, 28, 1)\n",
        "x_test_norm = x_test_norm.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "F5aza5Xpz-Mr"
      },
      "source": [
        "# train on the training set with some held back for validation #\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=None):\n",
        "\n",
        "    history = model.fit(x=train_features, y=train_label, \n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs, shuffle=True, \n",
        "                        validation_split=validation_split,\n",
        "                        verbose = 1)\n",
        "\n",
        "    # Gather the model's metrics after each round of training\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    return epochs, hist"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C_tbFXcMHu7",
        "trusted": true
      },
      "source": [
        " # Set up a CNN with Keras\n",
        " \n",
        "def create_CNN(learning_rate):\n",
        "    \"\"\"Create and compile a convolutional neural net.\"\"\"  \n",
        "    # Define the kind of model to use.\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, 6, activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, 4, activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, 2, activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=100, activation='softmax'))     \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                    loss=\"sparse_categorical_crossentropy\",\n",
        "                    metrics=['accuracy']) \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Nn2eBWKXTuaX",
        "trusted": true,
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bb6ce1-8454-4f47-c518-ed766c3f92e3"
      },
      "source": [
        "# Train and evalate CNN on ALL the datasets, \n",
        "# Train on 10000 + 60000 + 42000 to predict on 28000\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "batch_size = 500\n",
        "validation_split = 0.005 # 0.5% off bottom of each array\n",
        "start_time = time.time()\n",
        "\n",
        "convoluter = create_CNN(learning_rate)\n",
        " \n",
        "# TRAIN X8:\n",
        "for _ in range(8): #40 epochs total on each dataset\n",
        "    #x_test_norm:\n",
        "    epochs_CNN1, hist_CNN1 = train_model(convoluter, x_test_norm, y_test, epochs, batch_size, validation_split)\n",
        "    print(\"\\nFinished test set of 10000 in about {} seconds\\n\".format((round(time.time()-start_time,4))))\n",
        "    batch_time = time.time()\n",
        "    #x_train_norm:\n",
        "    epochs_CNN2, hist_CNN2 = train_model(convoluter, x_train_norm, y_train, epochs, batch_size, validation_split)\n",
        "    print(\"\\nFinished test set of 60000 in about {} seconds\\n\".format((round(time.time()-start_time,4))))\n",
        "    batch_time = time.time()\n",
        "    #k_train_norm:\n",
        "    epochs_CNN3, hist_CNN3 = train_model(convoluter, k_train_norm, k_labels, epochs, batch_size, validation_split)\n",
        "    print(\"\\nfinished test set of 42000 in about {} seconds\\n\".format((round(time.time()-start_time,4))))\n",
        "\n",
        "print (\"\\nTotal time: {} seconds is about {} minutes.\".format(round(time.time()-start_time,4),\n",
        "                                                              (time.time()-start_time)//60))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 1.7508 - accuracy: 0.5117 - val_loss: 0.6617 - val_accuracy: 0.7600\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.4260 - accuracy: 0.8760 - val_loss: 0.4153 - val_accuracy: 0.9000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.2676 - accuracy: 0.9214 - val_loss: 0.3055 - val_accuracy: 0.9200\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.1871 - accuracy: 0.9438 - val_loss: 0.2032 - val_accuracy: 0.9400\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.1336 - accuracy: 0.9595 - val_loss: 0.2185 - val_accuracy: 0.9400\n",
            "\n",
            "Finished test set of 10000 in about 9.9586 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1096 - accuracy: 0.9674 - val_loss: 0.2675 - val_accuracy: 0.9533\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0660 - accuracy: 0.9804 - val_loss: 0.2428 - val_accuracy: 0.9633\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0548 - accuracy: 0.9838 - val_loss: 0.2312 - val_accuracy: 0.9733\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.2342 - val_accuracy: 0.9733\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.2078 - val_accuracy: 0.9733\n",
            "\n",
            "Finished test set of 60000 in about 20.732 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 20ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0329 - val_accuracy: 0.9905\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0152 - val_accuracy: 0.9952\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0229 - val_accuracy: 0.9952\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 28.7788 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 7.2824e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 1.1342e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 2.6233e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 3.4014e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 30.6816 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.1528 - val_accuracy: 0.9767\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.1543 - val_accuracy: 0.9800\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.1563 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.1667 - val_accuracy: 0.9800\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.1799 - val_accuracy: 0.9800\n",
            "\n",
            "Finished test set of 60000 in about 41.4148 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 4.2986e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 49.1105 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.0911e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 8.9156e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 7.6700e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 6.6613e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 7.9419e-04 - accuracy: 0.9998 - val_loss: 3.6180e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 51.006 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.1454 - val_accuracy: 0.9700\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1618 - val_accuracy: 0.9800\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1644 - val_accuracy: 0.9800\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.2024 - val_accuracy: 0.9767\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.2069 - val_accuracy: 0.9800\n",
            "\n",
            "Finished test set of 60000 in about 61.6738 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.7008e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 7.5838e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 6.2313e-04 - accuracy: 0.9999 - val_loss: 2.0361e-04 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 69.3433 seconds\n",
            "\n",
            "Epoch 1/5\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.0103s). Check your callbacks.\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 1.2813e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.5521e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.5915e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 4.9804e-04 - accuracy: 0.9999 - val_loss: 1.7213e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 6.4716e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 71.2413 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1067 - val_accuracy: 0.9900\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1450 - val_accuracy: 0.9833\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1683 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.2023 - val_accuracy: 0.9833\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.2259 - val_accuracy: 0.9767\n",
            "\n",
            "Finished test set of 60000 in about 81.9044 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 5.4443e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 8.1605e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 8.0330e-04 - accuracy: 0.9999 - val_loss: 5.3231e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 8.6206e-04 - accuracy: 0.9997 - val_loss: 7.3043e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 8.5372e-04 - accuracy: 0.9998 - val_loss: 5.9000e-05 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 89.592 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 5.5074e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 7.8678e-08 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.1754e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 7.0571e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 91.4968 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1056 - val_accuracy: 0.9867\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.1224 - val_accuracy: 0.9900\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1331 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1588 - val_accuracy: 0.9867\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 6.5048e-04 - accuracy: 0.9998 - val_loss: 0.1880 - val_accuracy: 0.9833\n",
            "\n",
            "Finished test set of 60000 in about 102.1662 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.0546e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 9.3775e-04 - accuracy: 0.9998 - val_loss: 4.5149e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 4.7802e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 4.8034e-04 - accuracy: 0.9999 - val_loss: 1.6833e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 9.2009e-04 - accuracy: 0.9998 - val_loss: 2.5606e-05 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 109.8963 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 2.0981e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 6.4746e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 5.5516e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 111.8338 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1161 - val_accuracy: 0.9900\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1621 - val_accuracy: 0.9900\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1523 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1622 - val_accuracy: 0.9867\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 5.3687e-04 - accuracy: 0.9998 - val_loss: 0.1751 - val_accuracy: 0.9867\n",
            "\n",
            "Finished test set of 60000 in about 122.5281 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 7.8114e-04 - accuracy: 0.9999 - val_loss: 1.8626e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 6.8961e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 6.3474e-04 - accuracy: 0.9998 - val_loss: 0.0336 - val_accuracy: 0.9952\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 4.5605e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 3.8593e-04 - accuracy: 0.9999 - val_loss: 4.1303e-06 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 130.2306 seconds\n",
            "\n",
            "Epoch 1/5\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.5404e-05 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0103s). Check your callbacks.\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 5.7220e-08 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 7.3910e-08 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 5.3763e-04 - accuracy: 0.9999 - val_loss: 1.1065e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 4.9950e-04 - accuracy: 0.9999 - val_loss: 2.1696e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 1.3031e-04 - accuracy: 1.0000 - val_loss: 1.6689e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 132.133 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1279 - val_accuracy: 0.9867\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.1890 - val_accuracy: 0.9800\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.1230 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.1255 - val_accuracy: 0.9833\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1289 - val_accuracy: 0.9867\n",
            "\n",
            "Finished test set of 60000 in about 142.8354 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.1165e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.6090e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.4983e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.3365e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 4.3019e-04 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 150.5348 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 3.1948e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.2227e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 5.3268e-04 - accuracy: 0.9999 - val_loss: 2.4649e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 8.9054e-05 - accuracy: 1.0000 - val_loss: 1.3947e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 3.0792e-05 - accuracy: 1.0000 - val_loss: 1.0633e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Finished test set of 10000 in about 152.4464 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0647 - val_accuracy: 0.9933\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1093 - val_accuracy: 0.9900\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0934 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 7.4235e-05 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9867\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 2.1299e-05 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9867\n",
            "\n",
            "Finished test set of 60000 in about 163.1237 seconds\n",
            "\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 1.7759e-04 - accuracy: 1.0000 - val_loss: 9.1851e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "84/84 [==============================] - 1s 18ms/step - loss: 3.3562e-05 - accuracy: 1.0000 - val_loss: 4.8361e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 1.5458e-05 - accuracy: 1.0000 - val_loss: 3.2620e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 9.7422e-06 - accuracy: 1.0000 - val_loss: 2.6650e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "84/84 [==============================] - 2s 18ms/step - loss: 8.3211e-06 - accuracy: 1.0000 - val_loss: 2.3517e-06 - val_accuracy: 1.0000\n",
            "\n",
            "finished test set of 42000 in about 170.8532 seconds\n",
            "\n",
            "\n",
            "Total time: 170.8536 seconds is about 2.0 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28UmPOxH2PDk",
        "outputId": "a5b86b42-c2b1-4697-eb15-33ad4cbc06db"
      },
      "source": [
        "convoluter.evaluate(x_test_norm, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 8.6235e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.623475150670856e-05, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGE4a9c20pq"
      },
      "source": [
        "convoluter.save_model('digiteer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "euhy2XSez-Mr"
      },
      "source": [
        "if submit:\n",
        "    \n",
        "    def getKaggles():  \n",
        "        kaggles = pd.DataFrame(columns=['ImageId','Label'])  \n",
        "        predicts = convoluter.predict(kaggle_norm)\n",
        "        for j in range(len(kaggle_norm)):\n",
        "            probs = predicts[j] # one row of 10 probabilities \n",
        "            max_id = np.argmax(probs)   # index of top probability in row\n",
        "            kaggles.at[j,'ImageId'] = j+1\n",
        "            kaggles.at[j,'Label'] = max_id\n",
        "        return kaggles\n",
        "    \n",
        "    kaggles = getKaggles()\n",
        "    kaggles.to_csv('submission.csv', columns=[\"ImageId\",\"Label\"], index=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H7W-OKHUnsp"
      },
      "source": [
        "##Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6QCoQqRvRfb",
        "trusted": true,
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "06e7e00e-4f27-4acb-dc86-ac84538f4025"
      },
      "source": [
        "if not submit:\n",
        "# Plot a graph of the 'accuracy' metric vs. epochs:\n",
        "    plt.plot(epochs_CNN3,hist_CNN3[\"accuracy\"])\n",
        "    plt.plot(epochs_CNN3,hist_CNN3[\"val_accuracy\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}