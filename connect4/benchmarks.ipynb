{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "benchmarks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o4shGZVaZD2K"
      },
      "source": [
        "debug = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHPVSIp4ZD2C"
      },
      "source": [
        "# Install kaggle-environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA6lXk_-ZD2R"
      },
      "source": [
        "# Create ConnectX Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qy9Y3xghZD2T"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "!pip install 'kaggle-environments>=0.1.6'\n",
        "from kaggle_environments import evaluate, make, utils\n",
        "# Since utils.get_last_callable moved to agent.get_last_callable\n",
        "# See https://github.com/Kaggle/kaggle-environments/blob/e4a5651a3a0775b823fc27fe2c24b55cbd340420/kaggle_environments/agent.py#L37\n",
        "from kaggle_environments import agent as kaggle_env_agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "GxDd1F5_ZD2d"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "#env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aerdyYldw-Rq"
      },
      "source": [
        "# Check version of tensorflow\n",
        "!pip install 'tensorflow==1.15.0'\n",
        "import tensorflow as tf\n",
        "#tf.__version__\n",
        "!apt-get update\n",
        "!apt-get install -y cmake libopenmpi-dev python3-dev zlib1g-dev\n",
        "!pip install \"stable-baselines[mpi]==2.9.0\"\n",
        "from gym import spaces\n",
        "#For Trained Agent\n",
        "from stable_baselines import PPO1 \n",
        "from stable_baselines.common.policies import CnnPolicy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YO-Y8Xec7Tq"
      },
      "source": [
        "jd = json.load\n",
        "#df = pd.read_json(\"/content/5471908.json\", orient=\"split\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnkKfp_McDsw"
      },
      "source": [
        "#  with open(os.path(\"/content/5471908.json\"), 'rt') as fh:    \n",
        "        #firstline = fh.readline()\n",
        "        #assert firstline[0] == '#'\n",
        "#        js = json(fh, orient=\"split\")# (fh, index_col=None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1iPJQujZD2i"
      },
      "source": [
        "# Create an Agent\n",
        "\n",
        "To create the submission, an agent function should be fully encapsulated (no external dependencies).  \n",
        "\n",
        "When your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfMcBNTfXhYh"
      },
      "source": [
        "from test_agent_v9 import my_agent as test_agent\n",
        "from deep_lookahead import debug_agent as heuristic\n",
        "from quick_pick_submit import my_agent as quick_pick\n",
        "xtrain = PPO1.load('/content/xtrain.zip', env=None)\n",
        "modelX = PPO1.load('/content/modelX.zip', env=None, verbose=0)\n",
        "trained_model = PPO1.load('/content/trained.zip', env=None, verbose=0)\n",
        "trained_256 = PPO1.load('/content/trained_256.zip', env=None, verbose=0)\n",
        "scoresetA = PPO1.load('/content/scoresetA.zip', env=None, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjuz9pydarb"
      },
      "source": [
        "scoresetB20 = PPO1.load('/content/ssB_20k.zip', env=None, verbose=0)\n",
        "scoresetB40 = PPO1.load('/content/ssB_40k.zip', env=None, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Nag2SyZWPcY"
      },
      "source": [
        "#@ title Trained Agent wrapper for debug_model\n",
        "def trained_agent(obs, config, model=None, debug=False):\n",
        "    start = time.time()\n",
        "    \n",
        "    col, _ = trained_model.predict(np.array(obs['board']).reshape(6,7,1))\n",
        "\n",
        "    if (obs['board'][int(col)] != 0):\n",
        "        col = random.choice([col for col in range(config.columns) if obs.board[int(col)] == 0])\n",
        "        if debug:\n",
        "            print(\"\\n>>>> Agent is guessing... column\",col)      \n",
        "        return col\n",
        "    \n",
        "    if debug:\n",
        "        print(\"\\nTrained model predicted column:\", col)\n",
        "        print(\"Time taken =\", time.time() - start)\n",
        "\n",
        "    return col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN8B3DIaD0mW"
      },
      "source": [
        "#@ title Combineer\n",
        "def combineer(obs, config, model1=None, model2=None, model3=None, model4=None, model5=None, debug=False):\n",
        "    start = time.time()\n",
        "    board = np.array(obs['board']).reshape(6,7,1)\n",
        "\n",
        "    p1, _ = model1.predict(board)\n",
        "    p2, _ = model2.predict(board)\n",
        "    p3, _ = model3.predict(board)\n",
        "    #p4, _ = model3.predict(board)\n",
        "    #p5, _ = model3.predict(board)\n",
        "\n",
        "    #If two or three agree >> col, else if none agree col = p1\n",
        "    if p1!=p2 and p2==p3:\n",
        "        col = p2\n",
        "    else:  #all other combos, go with p1\n",
        "        col = p1\n",
        "    \n",
        "    if (obs['board'][int(col)] != 0):\n",
        "        col = random.choice([col for col in range(config.columns) if obs.board[int(col)] == 0])\n",
        "        if debug:\n",
        "            print(\"\\n>>>> Agent is guessing... column\",col)      \n",
        "        return int(col)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"\\nModel1 predicted: {}, Model2 predicted: {}, Model3 predicted: {}\".format(p1,p2,p3))\n",
        "        print(\"Consensus is: column\", col)\n",
        "        print(\"Time taken =\", time.time() - start)\n",
        "\n",
        "    return int(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbl8DSDEZD2n"
      },
      "source": [
        "# Test your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qysq-BZnk4cJ"
      },
      "source": [
        "#from heuristic_v8 import my_agent as heuristic\n",
        "#from test_agent_v6 import my_agent as test_agent\n",
        "#from submission import my_agent as sub3\n",
        "\n",
        "#from quick_look_v1 import my_agent as ql1\n",
        "#from quick_look_v2 import my_agent as ql2\n",
        "#from quick_look_v3 import my_agent as ql3\n",
        "\n",
        "#modelT = PPO1.load('/content/xtrain.zip', env=None)\n",
        "#modelX = PPO1.load('/content/modelX.zip', env=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Pa3uUqPZD2p"
      },
      "source": [
        "import random\n",
        "env.reset()\n",
        "START_TIME = time.time()\n",
        "\n",
        "debug = True\n",
        "test_run = debug # Set debug to True to test\n",
        "agent1 = lambda x,y: combineer(x,y, model1=modelX, model2=scoresetB40, model3=scoresetA, debug=True)\n",
        "agent2 = lambda x,y: test_agent(x,y, debug=False)\n",
        "#agent1 = lambda x,y: ql2(x,y, debug=False)\n",
        "#agent2 = lambda x,y: ql3(x,y, debug=False)\n",
        "\n",
        "while test_run:\n",
        "    env.reset()\n",
        "    if random.choice([True, False]):\n",
        "        env.run([agent1, agent2])\n",
        "        print(\"Agent order: [debug, agent2]\") \n",
        "    else:\n",
        "        env.run([agent2, agent1])\n",
        "        print(\"Agent order: [agent2, debug]\")\n",
        "\n",
        "    # Don't count ties as losses\n",
        "    if len(env.steps) == 43:\n",
        "        print('tie')\n",
        "        break\n",
        "    elif len(env.steps) % 2 == 1:\n",
        "        print('---- first (blue) agent LOST ----')\n",
        "        break\n",
        "    else:\n",
        "        print('++++ first (blue) agent WON ++++')\n",
        "        break\n",
        "\n",
        "print('\\n###### Game Over ######')\n",
        "print(f'Game time: {round(time.time()-START_TIME,3)}')\n",
        "#env.render(mode=\"ipython\", width=500, height=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Bqvith-orL"
      },
      "source": [
        "env.render(mode=\"ipython\", width=244, height=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKW2hg1XUNNg",
        "cellView": "form"
      },
      "source": [
        "#@title experimental_agent\n",
        "\n",
        "def experimental_agent(obs, config, ON_TIME=None, N_STEPS=2, cutoff_time=None, debug=False):\n",
        "\n",
        "    import numpy as np\n",
        "    import random\n",
        "    import time\n",
        "\n",
        "    # constants (given by game)\n",
        "    ROWS = config.rows\n",
        "    COLUMNS = config.columns\n",
        "    CNCTX = config.inarow\n",
        "    ## coefficients (weights on variable future outcomes)\n",
        "    A = 1     #my twos\n",
        "    B = 100    #my threes\n",
        "    C = 10000   #my fours         \n",
        "    D = -10    #opp-threes\n",
        "    E = -1000   #opp-fours\n",
        "    \n",
        "    cutoff_time_offset=0.2\n",
        "    if ON_TIME is None:\t\n",
        "        ON_TIME = time.time()   \n",
        "    if cutoff_time is None:\t\n",
        "        cutoff_time = (config.get('actTimeout', cutoff_time) - cutoff_time_offset)\n",
        "\n",
        "    #vary lookahead depth according to state of play:\n",
        "    if obs.board.count(1) < 2:\n",
        "        N_STEPS =      3\n",
        "    elif obs.board.count(1) <= ROWS*COLUMNS//(2*4):   # 3 up to one fourth\n",
        "        N_STEPS =      3 \n",
        "    elif obs.board.count(1) <= ROWS*COLUMNS//(2*2): # 4 up to one half\n",
        "        N_STEPS =      4\n",
        "    elif obs.board.count(1) <= 3*ROWS*COLUMNS//(2*4): # 5 up to three fourth\n",
        "        N_STEPS =      5\n",
        "    else:                                             \n",
        "        N_STEPS =      6\n",
        "\n",
        "    if debug:\n",
        "        if obs.board.count(1) == 0:\n",
        "            print(f'\"configuration\":{config}')  \n",
        "        print(f'\\n###### Agent marks {obs.board.count(1):02} ######') \n",
        "        print(f'###### Total marks {(obs.board.count(2) + obs.board.count(1)):02} ######') \n",
        "        print(f'Using {N_STEPS} step lookahead')\n",
        "\n",
        "    # Gets board at next step if agent drops piece in selected column\n",
        "    def drop_piece(grid, col, mark):\n",
        "        next_grid = grid.copy()\n",
        "        for row in range(ROWS-1, -1, -1):\n",
        "            if next_grid[row][col] == 0:\n",
        "                break\n",
        "        next_grid[row][col] = mark\n",
        "        return next_grid\n",
        "\n",
        "    # Helper function for get_score: checks if window satisfies heuristic conditions\n",
        "    def check_window(window, num_discs, piece):\n",
        "        return (window.count(piece) == num_discs and window.count(0) == CNCTX-num_discs)\n",
        "\n",
        "    # Helper function for get_score: counts number of windows satisfying specified heuristic conditions\n",
        "    def count_windows(grid, num_discs, piece):\n",
        "        num_windows = 0\n",
        "        # horizontal\n",
        "        for row in range(ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[row, col:col+CNCTX])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # vertical\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS):\n",
        "                window = list(grid[row:row+CNCTX, col])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # positive diagonal\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row+CNCTX), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # negative diagonal\n",
        "        for row in range(CNCTX-1, ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row-CNCTX, -1), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        return num_windows\n",
        "\n",
        "    # Helper function for minimax: calculates value of heuristic score\n",
        "    # for grid and checks if the grid is terminal\n",
        "    def get_score(grid, mark):\n",
        "        num_twos = count_windows(grid, 2, mark) #A\n",
        "        num_threes = count_windows(grid, 3, mark)  #B\n",
        "        num_fours = count_windows(grid, 4, mark)   #C\n",
        "        num_threes_opp = count_windows(grid, 3, mark%2+1) #D\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1)  #E     \n",
        "        score = A*num_twos + B*num_threes + C*num_fours + D*num_threes_opp + E*num_fours_opp\n",
        "        is_terminal = (not num_fours == 0) or (not num_fours_opp == 0) or (list(grid[0, :]).count(0) == 0)\n",
        "        return score, is_terminal\n",
        "\n",
        "    # Minimax algorithm with alphabeta pruning implementation:\n",
        "    def alphabeta(node, depth, alpha, beta, maximizingPlayer, mark, time_remaining):\n",
        "        node_score, is_terminal = get_score(node, mark)\n",
        "        if depth == 0 or is_terminal:\n",
        "             return node_score\n",
        "        if time_remaining <= cutoff_time_offset/5:  # 5 for number columns plus offset\n",
        "            depth = 1\n",
        "        valid_moves = [c for c in range(COLUMNS) if node[0][c] == 0]\n",
        "        if maximizingPlayer:\n",
        "            value = -np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark)\n",
        "                value = max(value, alphabeta(child, depth-1, alpha, beta, False, mark, time_remaining - time.time() ))\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "        else: #minimizing player\n",
        "            value = np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark%2+1)\n",
        "                value = min(value, alphabeta(child, depth-1, alpha, beta, True, mark, time_remaining - time.time()))\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "    # Uses alphabeta pruning to calculate value\n",
        "    # of dropping piece in selected column\n",
        "    def score_move(grid, col, mark, depth):\n",
        "        column_time = time.time()\n",
        "        time_remaining = column_time + (cutoff_time-cutoff_time_offset)/7 # 5 for number columns plus offset\n",
        "        next_grid = drop_piece(grid, col, mark)\n",
        "        if time.time()-ON_TIME > (col+1)*(cutoff_time-cutoff_time_offset)/7:\n",
        "            depth = 1\n",
        "        score = alphabeta(next_grid, depth-1, -np.Inf, np.Inf, False, mark, time_remaining - time.time())      \n",
        "        if debug:\n",
        "            time_remaining = time_remaining - time.time()\n",
        "            summary_stats = {\n",
        "                'column': col,\n",
        "                'score': score,\n",
        "                'column_time': round(time.time() - column_time, 4),\n",
        "                'col_time_remaining': round(time_remaining, 4),\n",
        "                'tot_time_elapsed': round(time.time() - ON_TIME, 3)\n",
        "            }\n",
        "            print(f'\"summary_stats\":{summary_stats}')\n",
        "        return score\n",
        "    \n",
        "    #########################\n",
        "    # Agent makes selection #\n",
        "    #########################\n",
        "\n",
        "    # Get list of valid moves\n",
        "    valid_moves = [c for c in range(COLUMNS) if obs.board[c] == 0]\n",
        "\n",
        "    # Convert the board to a 2D grid\n",
        "    grid = np.asarray(obs.board).reshape(ROWS, COLUMNS)\n",
        "\n",
        "    # Use the heuristic to assign a score to each possible board in the next step\n",
        "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, N_STEPS) for col in valid_moves]))\n",
        "\n",
        "    # Get a list of columns (moves) that maximize the heuristic\n",
        "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
        "    \n",
        "    #select column in order of preference (sometimes)\n",
        "    if True:\n",
        "        for pref in [3,4,2,6,0,5,1]: \n",
        "            if pref in max_cols:\n",
        "                choice = pref\n",
        "                break\n",
        "    else:\n",
        "        choice = random.choice(max_cols)\n",
        "    \n",
        "    if debug: print(\"Chosen column:\", choice)\n",
        "    return choice\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNRi7r05ZD22"
      },
      "source": [
        "# Evaluate your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSbzI5MMoXfK"
      },
      "source": [
        "def get_win_percentages(agent1, agent2, n_rounds=10):\n",
        "    # Use default Connect Four setup\n",
        "    import numpy as np\n",
        "    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n",
        "    # Agent 1 goes first (roughly) half the time          \n",
        "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
        "    # Agent 2 goes first (roughly) half the time      \n",
        "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
        "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 3))\n",
        "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 3))\n",
        "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
        "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))\n",
        "    return outcomes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trT_P9hL6WyB"
      },
      "source": [
        "trained = lambda x,y: trained_agent(x,y, model=time_trained, debug=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DdlZTzaojey"
      },
      "source": [
        "import time\n",
        "num_episodes = 10\n",
        "start = time.time()\n",
        "outcomes = get_win_percentages(trained, ql3, num_episodes)\n",
        "end = time.time()\n",
        "print (\"Total time:\",round(end-start,3),\"\\tAvg game time:\",round((end-start)/num_episodes,3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENaI4UNqng8O"
      },
      "source": [
        "import time\n",
        "num_episodes = 10\n",
        "start = time.time()\n",
        "outcomes = get_win_percentages(debug_agent, ql2, num_episodes)\n",
        "end = time.time()\n",
        "print (\"Total time:\",round(end-start,3),\"\\tAvg game time:\",round((end-start)/num_episodes,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPLx0YNvRBml"
      },
      "source": [
        "\n",
        "\n",
        "*   Agent 1 Win Percentage: 0.48\n",
        "*   Agent 2 Win Percentage: 0.52\n",
        "*   Number of Invalid Plays by Agent 1: 0\n",
        "*   Number of Invalid Plays by Agent 2: 0\n",
        "*   Total time: 224.808 \tAvg game time: 6.812\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KNU9JfGXZD23"
      },
      "source": [
        "def mean_reward(rewards):\n",
        "    return sum(r[0] for r in rewards) / float(len(rewards))\n",
        "\n",
        "# Run multiple episodes to estimate its performance.\n",
        "num_episodes = 33\n",
        "agent1 = test_agent\n",
        "agent2 = test_agent_v4   #  \"negamax\"\n",
        "if debug:\n",
        "    print(\"Debug Agent goes first:\", mean_reward(evaluate(\"connectx\", [agent1, agent2], num_episodes)))\n",
        "    print(\"Opp Agent goes first:\", mean_reward(evaluate(\"connectx\", [agent2, agent1], num_episodes)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpu8FGFZD26"
      },
      "source": [
        "# Step through your Agent\n",
        "Click on any column to place a checker there (\"manually select action\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FI-OlTJCZD2v"
      },
      "source": [
        "# Play as first position against random agent.\n",
        "trainer = env.train([None, \"negamax\"])\n",
        "\n",
        "observation = trainer.reset()\n",
        "\n",
        "while debug and not env.done:\n",
        "    my_action = agent1(observation, env.configuration)\n",
        "    print(\"My Action\", my_action)\n",
        "    observation, reward, done, info = trainer.step(my_action)\n",
        "    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsgusz84ZD3A"
      },
      "source": [
        "# Write Submission File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2VO9hB6OZD3B"
      },
      "source": [
        "import inspect\n",
        "import os\n",
        "\n",
        "def write_agent_to_file(function, file):\n",
        "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
        "        f.write(inspect.getsource(function))\n",
        "        print(function, \"written to\", file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zsi0unYcZD3I"
      },
      "source": [
        "submission_file = 'submission.py'\n",
        "write_agent_to_file(my_agent, submission_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rarkIiE8ZD3O"
      },
      "source": [
        "# Validate Submission\n",
        "Play your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n",
        "\n",
        "Why validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yvLra1maZD3Q"
      },
      "source": [
        "# Note: Stdout replacement is a temporary workaround.\n",
        "import sys\n",
        "out = sys.stdout\n",
        "submission = utils.read_file(\"submission.py\")\n",
        "agent = kaggle_env_agent.get_last_callable(submission)\n",
        "sys.stdout = out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hk7AixI3ZD3X"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "env.run([agent, agent])\n",
        "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Otabc-sZD3g"
      },
      "source": [
        "# Submit to Competition\n",
        "\n",
        "1. Save this kernel.\n",
        "2. View the commited version.\n",
        "3. Go to \"Data\" section and find submission.py file.\n",
        "4. Click \"Submit to Competition\"\n",
        "5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."
      ]
    }
  ]
}