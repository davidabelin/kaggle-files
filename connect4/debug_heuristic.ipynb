{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "debug_heuristic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yYpQzQvZD1-"
      },
      "source": [
        "Derived from a public notebook by https://www.kaggle.com/mrgeislinger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o4shGZVaZD2K"
      },
      "source": [
        "debug = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHPVSIp4ZD2C"
      },
      "source": [
        "# Install kaggle-environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA6lXk_-ZD2R"
      },
      "source": [
        "# Create ConnectX Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qy9Y3xghZD2T"
      },
      "source": [
        "import random as rd\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "!pip install 'kaggle-environments>=0.1.6'\n",
        "from kaggle_environments import evaluate, make, utils\n",
        "# Since utils.get_last_callable moved to agent.get_last_callable\n",
        "# See https://github.com/Kaggle/kaggle-environments/blob/e4a5651a3a0775b823fc27fe2c24b55cbd340420/kaggle_environments/agent.py#L37\n",
        "from kaggle_environments import agent as kaggle_env_agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "GxDd1F5_ZD2d"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "#env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aerdyYldw-Rq"
      },
      "source": [
        "# Check version of tensorflow\n",
        "!pip install 'tensorflow==1.15.0'\n",
        "import tensorflow as tf\n",
        "#tf.__version__\n",
        "!apt-get update\n",
        "!apt-get install -y cmake libopenmpi-dev python3-dev zlib1g-dev\n",
        "!pip install \"stable-baselines[mpi]==2.9.0\"\n",
        "from gym import spaces\n",
        "#For Trained Agent\n",
        "from stable_baselines import PPO1 \n",
        "from stable_baselines.common.policies import CnnPolicy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Nag2SyZWPcY",
        "cellView": "form"
      },
      "source": [
        "#@title Trained Agent\n",
        "def trained_agent(obs, config, model=None, debug=False):\n",
        "    start = time.time()\n",
        "    #Import saved model trained on Agent Heuristic\n",
        "    if model is None:\n",
        "        trained_model = stable_baselines.PPO1.load('/content/trained.zip', env=None, verbose=0)\n",
        "    else:\n",
        "        trained_model = model\n",
        "    \n",
        "    # Use the trained model to select a column\n",
        "    col, _ = trained_model.predict(np.array(obs['board']).reshape(6,7,1))\n",
        "    # Check if selected column is valid\n",
        "    is_valid = (obs['board'][int(col)] == 0)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"\\nTrained model predicted column:\", col)\n",
        "        print(\"Time taken =\", time.time() - start)\n",
        "    \n",
        "    # If not valid, select random move. \n",
        "    if is_valid:\n",
        "        return int(col)\n",
        "    else:\n",
        "        return random.choice([col for col in range(config.columns) if obs.board[int(col)] == 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1iPJQujZD2i"
      },
      "source": [
        "# Create an Agent\n",
        "\n",
        "To create the submission, an agent function should be fully encapsulated (no external dependencies).  \n",
        "\n",
        "When your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgFdQ0O2zCsQ"
      },
      "source": [
        "def debug_agent(obs, config, N_STEPS=2, debug=False):\n",
        "    ''' Copy and paste your agent here '''\n",
        "    \n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PsFqJ0y9AhZ"
      },
      "source": [
        "#@ title debug_agent\r\n",
        "def debug_agent(obs, config, N_STEPS=2, debug=False, df=None):\r\n",
        "    ''' Copy and paste your agent here '''\r\n",
        "    import numpy as np\r\n",
        "    import random\r\n",
        "    import time\r\n",
        "\r\n",
        "    ########################### Regular pruner ################\r\n",
        "    # global vars\r\n",
        "    global glob_it\r\n",
        "    # constants (given by game)\r\n",
        "    ROWS = config.rows\r\n",
        "    COLUMNS = config.columns\r\n",
        "    CNCTX = config.inarow\r\n",
        "    ## coefficients\r\n",
        "    A = 2     #my twos\r\n",
        "    B = 20    #my threes\r\n",
        "    C = 200   #my fours\r\n",
        "    D = -1    #opp-twos\r\n",
        "    E = -10    #opp-threes\r\n",
        "    F = -100   #opp-fours\r\n",
        "    \r\n",
        "    # vary lookahead depth according to state of play:\r\n",
        "    if obs.board.count(0) >= 6*(ROWS*COLUMNS//7):\r\n",
        "        N_STEPS =       2     \r\n",
        "    elif obs.board.count(0) >= 5*(ROWS*COLUMNS//7):\r\n",
        "        N_STEPS =       3\r\n",
        "    elif obs.board.count(0) >= 4*(ROWS*COLUMNS//7):\r\n",
        "        N_STEPS =       4  \r\n",
        "    elif obs.board.count(0) >= 3*(ROWS*COLUMNS//7):\r\n",
        "        N_STEPS =       5\r\n",
        "    elif obs.board.count(0) >= 2*(ROWS*COLUMNS//7):\r\n",
        "        N_STEPS =       6 \r\n",
        "    else:    \r\n",
        "        N_STEPS =       7\r\n",
        "    \r\n",
        "    if debug:\r\n",
        "        if obs.board.count(1) == 0:\r\n",
        "            print(f'\"configuration\":{config}')  \r\n",
        "        print(f'\\n###### Player {obs.mark} Turn {obs.board.count(obs.mark):02} ######') \r\n",
        "        print('Board:', np.reshape(obs.board, (6,7)))\r\n",
        "        print(f'Using {N_STEPS} step lookahead')\r\n",
        "\r\n",
        "    # Gets board at next step if agent drops piece in selected column\r\n",
        "    def drop_piece(grid, col, mark):\r\n",
        "        next_grid = grid.copy()\r\n",
        "        for row in range(ROWS-1, -1, -1):\r\n",
        "            if next_grid[row][col] == 0:\r\n",
        "                break\r\n",
        "        next_grid[row][col] = mark\r\n",
        "        return next_grid\r\n",
        "\r\n",
        "    # Helper function for get_score: checks if window satisfies heuristic conditions\r\n",
        "    def check_window(window, num_discs, piece):\r\n",
        "        return (window.count(piece) == num_discs and window.count(0) == CNCTX-num_discs)\r\n",
        "\r\n",
        "    # Helper function for get_score: counts number of windows satisfying specified heuristic conditions\r\n",
        "    def count_windows(grid, num_discs, piece):\r\n",
        "        num_windows = 0\r\n",
        "        # horizontal\r\n",
        "        for row in range(ROWS):\r\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\r\n",
        "                window = list(grid[row, col:col+CNCTX])\r\n",
        "                if check_window(window, num_discs, piece):\r\n",
        "                    num_windows += 1\r\n",
        "        # vertical\r\n",
        "        for row in range(ROWS-(CNCTX-1)):\r\n",
        "            for col in range(COLUMNS):\r\n",
        "                window = list(grid[row:row+CNCTX, col])\r\n",
        "                if check_window(window, num_discs, piece):\r\n",
        "                    num_windows += 1\r\n",
        "        # positive diagonal\r\n",
        "        for row in range(ROWS-(CNCTX-1)):\r\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\r\n",
        "                window = list(grid[range(row, row+CNCTX), range(col, col+CNCTX)])\r\n",
        "                if check_window(window, num_discs, piece):\r\n",
        "                    num_windows += 1\r\n",
        "        # negative diagonal\r\n",
        "        for row in range(CNCTX-1, ROWS):\r\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\r\n",
        "                window = list(grid[range(row, row-CNCTX, -1), range(col, col+CNCTX)])\r\n",
        "                if check_window(window, num_discs, piece):\r\n",
        "                    num_windows += 1\r\n",
        "        return num_windows\r\n",
        "        \r\n",
        "    # Quickly checks to see if the game could be won or lost in next step\r\n",
        "    def check_terminal(grid, mark):\r\n",
        "        num_fours = count_windows(grid, 4, mark)   #C\r\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1)  #F\r\n",
        "        is_terminal = (num_fours != 0) or (num_fours_opp != 0) or (list(grid[0, :]).count(0) == 0)\r\n",
        "        return is_terminal\r\n",
        "    \r\n",
        "    # Helper function for alphabeta: calculates value of heuristic for grid\r\n",
        "    def get_score(grid, mark):\r\n",
        "        num_fours = count_windows(grid, 4, mark)   #C\r\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1)  #F\r\n",
        "        num_twos = count_windows(grid, 2, mark) #A\r\n",
        "        num_threes = count_windows(grid, 3, mark)  #B\r\n",
        "        num_twos_opp = count_windows(grid, 2, mark%2+1) #D\r\n",
        "        num_threes_opp = count_windows(grid, 3, mark%2+1) #E\r\n",
        "        score = A*num_twos + B*num_threes + C*num_fours + D*num_twos_opp + E*num_threes_opp + F*num_fours_opp\r\n",
        "        is_terminal = (num_fours != 0) or (num_fours_opp != 0) or (list(grid[0, :]).count(0) == 0)\r\n",
        "        return score, is_terminal\r\n",
        "\r\n",
        "    # Minimax with alphabeta pruning implementation:\r\n",
        "    def alphabeta(node, depth, alpha, beta, maximizingPlayer, mark):\r\n",
        "        node_score, is_terminal = get_score(node, mark)\r\n",
        "        if depth == 0 or is_terminal:\r\n",
        "             return node_score\r\n",
        "\r\n",
        "        valid_moves = [c for c in range(COLUMNS) if node[0][c] == 0]\r\n",
        "        if maximizingPlayer:\r\n",
        "            value = -np.Inf\r\n",
        "            for col in valid_moves:\r\n",
        "                child = drop_piece(node, col, mark)\r\n",
        "                value = max(value, alphabeta(child, depth-1, alpha, beta, False, mark))\r\n",
        "                alpha = max(alpha, value)\r\n",
        "                if alpha >= beta:\r\n",
        "                    break\r\n",
        "            return value\r\n",
        "\r\n",
        "        else: #minimizing player\r\n",
        "            value = np.Inf\r\n",
        "            for col in valid_moves:\r\n",
        "                child = drop_piece(node, col, mark%2+1)\r\n",
        "                value = min(value, alphabeta(child, depth-1, alpha, beta, True, mark))\r\n",
        "                beta = min(beta, value)\r\n",
        "                if alpha >= beta:\r\n",
        "                    break\r\n",
        "            return value\r\n",
        "\r\n",
        "    # Uses alphabeta pruning to calculate value\r\n",
        "    # of dropping piece in selected column\r\n",
        "    def score_move(grid, col, mark, depth):\r\n",
        "        go = time.time()\r\n",
        "        next_grid = drop_piece(grid, col, mark)\r\n",
        "        score = alphabeta(next_grid, depth-1, -np.Inf, np.Inf, False, mark)\r\n",
        "        if debug:\r\n",
        "            summary_stats = {\r\n",
        "                'column': col,\r\n",
        "                'score': score,\r\n",
        "                'column time': round(time.time() - go, 5),\r\n",
        "                'time_left': round(2.0 - (time.time() - choice_time), 5)           \r\n",
        "            }\r\n",
        "            print(f'\"summary_stats\":{summary_stats}')\r\n",
        "        return score\r\n",
        "    \r\n",
        "    def first_pass(grid, col, mark):\r\n",
        "        player_is_terminal = check_terminal(drop_piece(grid, col, mark), mark)\r\n",
        "        opp_is_terminal = check_terminal(drop_piece(grid, col, mark%2+1), mark%2+1)\r\n",
        "        return opp_is_terminal or player_is_terminal\r\n",
        "    \r\n",
        "    #########################\r\n",
        "    # Agent makes selection #\r\n",
        "    #########################\r\n",
        "\r\n",
        "    # Get list of valid moves\r\n",
        "    valid_moves = [c for c in range(COLUMNS) if obs.board[c] == 0]\r\n",
        "\r\n",
        "    # Convert the board to a 2D grid\r\n",
        "    grid = np.asarray(obs.board).reshape(ROWS, COLUMNS)\r\n",
        "\r\n",
        "    # Do a quick pass to see if there is a terminal node on the surface \r\n",
        "    choice_time = time.time()\r\n",
        "    quick_pick = False\r\n",
        "    for col in valid_moves:\r\n",
        "        quick_pick = first_pass(grid, col, obs.mark)\r\n",
        "        if quick_pick:\r\n",
        "            choice = col   \r\n",
        "            if debug:\r\n",
        "                print(\"Column {} is terminal.\".format(choice))\r\n",
        "            break\r\n",
        "    \r\n",
        "    if not quick_pick:   \r\n",
        "        # Use the heuristic to assign a score to each possible board in the next step\r\n",
        "        scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, N_STEPS) for col in valid_moves]))\r\n",
        "\r\n",
        "        # Get a list of columns (moves) that maximize the heuristic\r\n",
        "        max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\r\n",
        "        \r\n",
        "        #select column in order of preference\r\n",
        "        for pref in [3,4,2]: \r\n",
        "            if pref in max_cols:\r\n",
        "                choice = pref\r\n",
        "                break\r\n",
        "            else:\r\n",
        "                choice = random.choice(max_cols)\r\n",
        "    if debug:\r\n",
        "        print(\"Chosen column:\", choice)\r\n",
        "        print(\"Choice took:\", round(time.time()-choice_time,5))\r\n",
        "\r\n",
        "    if not df is None:\r\n",
        "        df.iloc[glob_it] = [choice]+[obs.step]+[obs.mark]+[x for x in obs.board]\r\n",
        "        glob_it += 1\r\n",
        "        \r\n",
        "    return choice\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbl8DSDEZD2n"
      },
      "source": [
        "# Test your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qysq-BZnk4cJ"
      },
      "source": [
        "#from test_agent_v4 import my_agent as test_agent_v4\n",
        "from experimental_agent_v8 import my_agent as pruner\n",
        "#from heuristic_v8 import my_agent as heuristic\n",
        "#from test_agent_v9 import my_agent as test_agent\n",
        "from quick_look_v0 import my_agent as quick_pick"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYwsz1xwUNRY",
        "cellView": "form"
      },
      "source": [
        "#@title subagent\n",
        "def sub_agent(obs, config, N_STEPS=2, debug=False):\n",
        "\n",
        "    import numpy as np\n",
        "    import random\n",
        "    import time\n",
        "\n",
        "    ########################### Regular pruner ################\n",
        "    # constants (given by game)\n",
        "    ROWS = config.rows\n",
        "    COLUMNS = config.columns\n",
        "    CNCTX = config.inarow\n",
        "    ## coefficients\n",
        "    A = 2     #my twos\n",
        "    B = 20    #my threes\n",
        "    C = 200   #my fours\n",
        "    D = -1    #opp-twos\n",
        "    E = -10    #opp-threes\n",
        "    F = -100   #opp-fours\n",
        "    \n",
        "    # vary lookahead depth according to state of play:\n",
        "    if obs.board.count(0) >= ROWS*COLUMNS//2:\n",
        "        N_STEPS =      2\n",
        "    else:\n",
        "        N_STEPS =      3  # deeper search after half the board is filled\n",
        "\n",
        "    if debug:\n",
        "        if obs.board.count(1) == 0:\n",
        "            print(f'\"configuration\":{config}')  \n",
        "        print(f'\\n###### Agent Turn {obs.board.count(1):02} ######') \n",
        "        print(f'Using {N_STEPS} step lookahead')\n",
        "\n",
        "    # Gets board at next step if agent drops piece in selected column\n",
        "    def drop_piece(grid, col, mark):\n",
        "        next_grid = grid.copy()\n",
        "        for row in range(ROWS-1, -1, -1):\n",
        "            if next_grid[row][col] == 0:\n",
        "                break\n",
        "        next_grid[row][col] = mark\n",
        "        return next_grid\n",
        "\n",
        "    # Helper function for get_score: checks if window satisfies heuristic conditions\n",
        "    def check_window(window, num_discs, piece):\n",
        "        return (window.count(piece) == num_discs and window.count(0) == CNCTX-num_discs)\n",
        "\n",
        "    # Helper function for get_score: counts number of windows satisfying specified heuristic conditions\n",
        "    def count_windows(grid, num_discs, piece):\n",
        "        num_windows = 0\n",
        "        # horizontal\n",
        "        for row in range(ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[row, col:col+CNCTX])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # vertical\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS):\n",
        "                window = list(grid[row:row+CNCTX, col])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # positive diagonal\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row+CNCTX), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # negative diagonal\n",
        "        for row in range(CNCTX-1, ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row-CNCTX, -1), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        return num_windows\n",
        "\n",
        "    # Helper function for alphabeta: calculates value of heuristic for grid\n",
        "    def get_score(grid, mark):\n",
        "        num_fours = count_windows(grid, 4, mark)   #C\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1)  #F\n",
        "        is_terminal = (num_fours != 0) or (num_fours_opp != 0) or (list(grid[0, :]).count(0) == 0)\n",
        "        #if debug:\n",
        "        #    print (list(grid[0, :]).count(0))\n",
        "        if is_terminal:\n",
        "            return C*num_fours + F*num_fours_opp, is_terminal\n",
        "        num_twos = count_windows(grid, 2, mark) #A\n",
        "        num_threes = count_windows(grid, 3, mark)  #B\n",
        "        num_twos_opp = count_windows(grid, 2, mark%2+1) #D\n",
        "        num_threes_opp = count_windows(grid, 3, mark%2+1) #E\n",
        "        score = A*num_twos + B*num_threes + C*num_fours + D*num_twos_opp + E*num_threes_opp + F*num_fours_opp\n",
        "        return score, is_terminal\n",
        "\n",
        "    # Minimax with alphabeta pruning implementation:\n",
        "    def alphabeta(node, depth, alpha, beta, maximizingPlayer, mark):\n",
        "        node_score, is_terminal = get_score(node, mark)\n",
        "        if depth == 0 or is_terminal:\n",
        "             return node_score\n",
        "\n",
        "        valid_moves = [c for c in range(COLUMNS) if node[0][c] == 0]\n",
        "        if maximizingPlayer:\n",
        "            value = -np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark)\n",
        "                value = max(value, alphabeta(child, depth-1, alpha, beta, False, mark))\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "        else: #minimizing player\n",
        "            value = np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark%2+1)\n",
        "                value = min(value, alphabeta(child, depth-1, alpha, beta, True, mark))\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "    # Uses alphabeta pruning to calculate value\n",
        "    # of dropping piece in selected column\n",
        "    def score_move(grid, col, mark, depth):\n",
        "        next_grid = drop_piece(grid, col, mark)\n",
        "        score = alphabeta(next_grid, depth-1, -np.Inf, np.Inf, False, mark)\n",
        "        if debug:\n",
        "            summary_stats = {\n",
        "                'column': col,\n",
        "                'score': score,\n",
        "            }\n",
        "            print(f'\"summary_stats\":{summary_stats}')\n",
        "        return score\n",
        "    \n",
        "    def first_pass(grid, col, mark):\n",
        "        score, self_is_terminal = get_score(drop_piece(grid, col, mark), mark)\n",
        "        score, opp_is_terminal = get_score(drop_piece(grid, col, mark%2+1), mark%2+1)\n",
        "        return self_is_terminal or opp_is_terminal\n",
        "    \n",
        "    #########################\n",
        "    # Agent makes selection #\n",
        "    #########################\n",
        "\n",
        "    # Get list of valid moves\n",
        "    valid_moves = [c for c in range(COLUMNS) if obs.board[c] == 0]\n",
        "\n",
        "    # Convert the board to a 2D grid\n",
        "    grid = np.asarray(obs.board).reshape(ROWS, COLUMNS)\n",
        "\n",
        "    # Do a quick pass at depth zero to see if there is a positive terminal node\n",
        "    quick_pick = False\n",
        "    for col in valid_moves:\n",
        "        quick_pick = first_pass(grid, col, obs.mark)\n",
        "        if quick_pick:\n",
        "            choice = col   \n",
        "            if debug:\n",
        "                print(\"Column {} is terminal.\".format(choice))\n",
        "            break\n",
        "    if not quick_pick:   \n",
        "        # Use the heuristic to assign a score to each possible board in the next step\n",
        "        scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, N_STEPS) for col in valid_moves]))\n",
        "\n",
        "        # Get a list of columns (moves) that maximize the heuristic\n",
        "        max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
        "        \n",
        "        #select column in order of preference\n",
        "        for pref in [3,4,2]: \n",
        "            if pref in max_cols:\n",
        "                choice = pref\n",
        "                break\n",
        "            else:\n",
        "                choice = random.choice(max_cols)\n",
        "    if debug:\n",
        "        print(\"Chosen column:\", choice)\n",
        "    return choice\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZrEVXesE9aR"
      },
      "source": [
        "gp = np.zeros((100,45))\r\n",
        "glob_it = 0\r\n",
        "gameplay_df = pd.DataFrame(gp, columns=[\"choice\"]+[\"step\"]+[\"mark\"]+['b' + str(x) for x in range(42)],dtype='int64')\r\n",
        "gameplay_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Pa3uUqPZD2p"
      },
      "source": [
        "START_TIME = time.time()\n",
        "\n",
        "debug = True\n",
        "test_run = debug # Set debug to True to test\n",
        "agent1 = lambda x,y: debug_agent(x,y, debug=True, df=gameplay_df)\n",
        "#agent2 = lambda x,y: dba(x,y,debug=False)\n",
        "agent2 = pruner#test_agent\n",
        "\n",
        "while test_run:\n",
        "    env.reset()\n",
        "    if rd.choice([True, False]):\n",
        "        env.run([agent1, agent2])\n",
        "        print(\"Agent order: [debug_agent, opponent]\") \n",
        "    else:\n",
        "        env.run([agent2, agent1])\n",
        "        print(\"Agent order: [opponent, debug_agent]\")\n",
        "\n",
        "    # Don't count ties as losses\n",
        "    if len(env.steps) == 43:\n",
        "        print('tie')\n",
        "        break\n",
        "    elif len(env.steps) % 2 == 1:\n",
        "        print('--- b1ue agent lost ---')\n",
        "        break\n",
        "    else:\n",
        "        print('+++ b1ue agent won +++')\n",
        "        break\n",
        "\n",
        "print('\\n###### Game Over ######')\n",
        "print(f'Game time: {round(time.time()-START_TIME,3)}')\n",
        "#env.render(mode=\"ipython\", width=500, height=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Bqvith-orL"
      },
      "source": [
        "env.render(mode=\"ipython\", width=244, height=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNRi7r05ZD22"
      },
      "source": [
        "# Evaluate your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSbzI5MMoXfK"
      },
      "source": [
        "def get_win_percentages(agent1, agent2, n_rounds=10):\n",
        "    # Use default Connect Four setup\n",
        "    import numpy as np\n",
        "    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n",
        "    # Agent 1 goes first (roughly) half the time          \n",
        "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
        "    # Agent 2 goes first (roughly) half the time      \n",
        "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
        "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 3))\n",
        "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 3))\n",
        "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
        "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))\n",
        "    return outcomes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DdlZTzaojey"
      },
      "source": [
        "import time\n",
        "num_episodes = 12\n",
        "start = time.time()\n",
        "outcomes = get_win_percentages(agent1, agent2, num_episodes)\n",
        "end = time.time()\n",
        "print (\"Total time:\",round(end-start,3),\"\\tAvg game time:\",round((end-start)/num_episodes,3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENaI4UNqng8O"
      },
      "source": [
        "import time\n",
        "num_episodes = 111\n",
        "start = time.time()\n",
        "outcomes = get_win_percentages(test_agent, test_agent_v4, num_episodes)\n",
        "end = time.time()\n",
        "print (\"Total time:\",round(end-start,3),\"\\tAvg game time:\",round((end-start)/num_episodes,3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPLx0YNvRBml"
      },
      "source": [
        "\n",
        "\n",
        "*   Agent 1 Win Percentage: 0.48\n",
        "*   Agent 2 Win Percentage: 0.52\n",
        "*   Number of Invalid Plays by Agent 1: 0\n",
        "*   Number of Invalid Plays by Agent 2: 0\n",
        "*   Total time: 224.808 \tAvg game time: 6.812\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KNU9JfGXZD23"
      },
      "source": [
        "def mean_reward(rewards):\n",
        "    return sum(r[0] for r in rewards) / float(len(rewards))\n",
        "\n",
        "# Run multiple episodes to estimate its performance.\n",
        "num_episodes = 33\n",
        "agent1 = test_agent\n",
        "agent2 = test_agent_v4   #  \"negamax\"\n",
        "if debug:\n",
        "    print(\"Debug Agent goes first:\", mean_reward(evaluate(\"connectx\", [agent1, agent2], num_episodes)))\n",
        "    print(\"Opp Agent goes first:\", mean_reward(evaluate(\"connectx\", [agent2, agent1], num_episodes)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpu8FGFZD26"
      },
      "source": [
        "# Step through your Agent\n",
        "Click on any column to place a checker there (\"manually select action\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FI-OlTJCZD2v"
      },
      "source": [
        "# Play as first position against random agent.\n",
        "trainer = env.train([None, \"negamax\"])\n",
        "\n",
        "observation = trainer.reset()\n",
        "\n",
        "while debug and not env.done:\n",
        "    my_action = agent1(observation, env.configuration)\n",
        "    print(\"My Action\", my_action)\n",
        "    observation, reward, done, info = trainer.step(my_action)\n",
        "    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsgusz84ZD3A"
      },
      "source": [
        "# Write Submission File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2VO9hB6OZD3B"
      },
      "source": [
        "import inspect\n",
        "import os\n",
        "\n",
        "def write_agent_to_file(function, file):\n",
        "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
        "        f.write(inspect.getsource(function))\n",
        "        print(function, \"written to\", file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zsi0unYcZD3I"
      },
      "source": [
        "submission_file = 'submission.py'\n",
        "write_agent_to_file(my_agent, submission_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rarkIiE8ZD3O"
      },
      "source": [
        "# Validate Submission\n",
        "Play your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n",
        "\n",
        "Why validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yvLra1maZD3Q"
      },
      "source": [
        "# Note: Stdout replacement is a temporary workaround.\n",
        "import sys\n",
        "out = sys.stdout\n",
        "submission = utils.read_file(\"submission.py\")\n",
        "agent = kaggle_env_agent.get_last_callable(submission)\n",
        "sys.stdout = out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hk7AixI3ZD3X"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "env.run([agent, agent])\n",
        "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Otabc-sZD3g"
      },
      "source": [
        "# Submit to Competition\n",
        "\n",
        "1. Save this kernel.\n",
        "2. View the commited version.\n",
        "3. Go to \"Data\" section and find submission.py file.\n",
        "4. Click \"Submit to Competition\"\n",
        "5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."
      ]
    }
  ]
}