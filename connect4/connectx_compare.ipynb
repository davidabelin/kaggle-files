{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "connectx_compare.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yYpQzQvZD1-"
      },
      "source": [
        "Derived from a public notebook by https://www.kaggle.com/mrgeislinger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o4shGZVaZD2K"
      },
      "source": [
        "debug = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHPVSIp4ZD2C"
      },
      "source": [
        "# Install kaggle-environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "dBBtKD-SZD2D"
      },
      "source": [
        "# 1. Enable Internet in the Kernel (Settings side pane)\n",
        "\n",
        "# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n",
        "# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n",
        "\n",
        "# ConnectX environment was defined in v0.1.6\n",
        "!pip install 'kaggle-environments>=0.1.6'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA6lXk_-ZD2R"
      },
      "source": [
        "# Create ConnectX Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qy9Y3xghZD2T"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from kaggle_environments import evaluate, make, utils\n",
        "# Since utils.get_last_callable moved to agent.get_last_callable\n",
        "# See https://github.com/Kaggle/kaggle-environments/blob/e4a5651a3a0775b823fc27fe2c24b55cbd340420/kaggle_environments/agent.py#L37\n",
        "from kaggle_environments import agent as kaggle_env_agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "GxDd1F5_ZD2d"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "#env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aerdyYldw-Rq"
      },
      "source": [
        "# Check version of tensorflow\n",
        "!pip install 'tensorflow==1.15.0'\n",
        "import tensorflow as tf\n",
        "#tf.__version__\n",
        "!apt-get update\n",
        "!apt-get install -y cmake libopenmpi-dev python3-dev zlib1g-dev\n",
        "!pip install \"stable-baselines[mpi]==2.9.0\"\n",
        "from gym import spaces\n",
        "from stable_baselines import PPO1 \n",
        "from stable_baselines.common.policies import CnnPolicy\n",
        "\n",
        "#model = PPO1.load('/content/trained_prunerZ.zip', env=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1iPJQujZD2i"
      },
      "source": [
        "# Create an Agent\n",
        "\n",
        "To create the submission, an agent function should be fully encapsulated (no external dependencies).  \n",
        "\n",
        "When your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s9n1vmsEHeu"
      },
      "source": [
        "blank = np.zeros((6,7))\n",
        "list(blank[0]).count(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbY_oLgFpvdZ"
      },
      "source": [
        "#@ title Test Agent\n",
        "def test_agent(obs, config, debug=False):\n",
        "\n",
        "    import numpy as np\n",
        "    import random\n",
        "    import time\n",
        "\n",
        "    # constants (given by game)\n",
        "    ROWS = config.rows\n",
        "    COLUMNS = config.columns\n",
        "    CNCTX = config.inarow\n",
        "    ## coefficients (weights on variable future outcomes)\n",
        "    A = 1     #my twos\n",
        "    B = 100    #my threes\n",
        "    C = 10000   #my fours         \n",
        "    D = -10    #opp-threes\n",
        "    E = -1000   #opp-fours\n",
        "    \n",
        "    # vary lookahead depth according to state of play:\n",
        "    if obs.board.count(1) < 2:\n",
        "        N_STEPS =      1\n",
        "    elif obs.board.count(1) <= ROWS*COLUMNS//(2*3): # 2 up to one third\n",
        "        N_STEPS =      2 \n",
        "    elif obs.board.count(1) <= 3*ROWS*COLUMNS//(2*4): # 3 up to three fouths\n",
        "        N_STEPS =      3\n",
        "    else:                                             # 4 last 25% of game\n",
        "        N_STEPS =      4\n",
        "\n",
        "    if debug:\n",
        "        if obs.board.count(1) == 0:\n",
        "            print(f'\"configuration\":{config}')  \n",
        "        print(f'\\n###### Agent mark {obs.board.count(1):02} ######') \n",
        "        print(f'###### Game marks {(obs.board.count(2) + obs.board.count(1)):02} ######') \n",
        "        print(f'Using {N_STEPS} step lookahead')\n",
        "\n",
        "    # Gets board at next step if agent drops piece in selected column\n",
        "    def drop_piece(grid, col, mark):\n",
        "        next_grid = grid.copy()\n",
        "        for row in range(ROWS-1, -1, -1):\n",
        "            if next_grid[row][col] == 0:\n",
        "                break\n",
        "        next_grid[row][col] = mark\n",
        "        return next_grid\n",
        "\n",
        "    # Helper function for get_score: checks if window satisfies heuristic conditions\n",
        "    def check_window(window, num_discs, piece):\n",
        "        return (window.count(piece) == num_discs and window.count(0) == CNCTX-num_discs)\n",
        "\n",
        "    # Helper function for get_score: counts number of windows satisfying specified heuristic conditions\n",
        "    def count_windows(grid, num_discs, piece):\n",
        "        num_windows = 0\n",
        "        # horizontal\n",
        "        for row in range(ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[row, col:col+CNCTX])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # vertical\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS):\n",
        "                window = list(grid[row:row+CNCTX, col])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # positive diagonal\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row+CNCTX), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # negative diagonal\n",
        "        for row in range(CNCTX-1, ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row-CNCTX, -1), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        return num_windows\n",
        "\n",
        "    # Helper function for minimax: calculates value of heuristic score\n",
        "    # for grid and checks if the grid is terminal\n",
        "    def get_score(grid, mark):\n",
        "        num_twos = count_windows(grid, 2, mark) #A\n",
        "        num_threes = count_windows(grid, 3, mark)  #B\n",
        "        num_fours = count_windows(grid, 4, mark)   #C\n",
        "        num_threes_opp = count_windows(grid, 3, mark%2+1) #D\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1)  #E     \n",
        "        score = A*num_twos + B*num_threes + C*num_fours + D*num_threes_opp + E*num_fours_opp\n",
        "        is_terminal = (not num_fours == 0) or (not num_fours_opp == 0) or (list(grid[0, :]).count(0) == 0)\n",
        "        return score, is_terminal\n",
        "\n",
        "    # Minimax algorithm with alphabeta pruning implementation:\n",
        "    def alphabeta(node, depth, alpha, beta, maximizingPlayer, mark):\n",
        "        node_score, is_terminal = get_score(node, mark)\n",
        "        if depth == 0 or is_terminal:\n",
        "             return node_score\n",
        "\n",
        "        valid_moves = [c for c in range(COLUMNS) if node[0][c] == 0]\n",
        "        if maximizingPlayer:\n",
        "            value = -np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark)\n",
        "                value = max(value, alphabeta(child, depth-1, alpha, beta, False, mark))\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "        else: #minimizing player\n",
        "            value = np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark%2+1)\n",
        "                value = min(value, alphabeta(child, depth-1, alpha, beta, True, mark))\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "    # Uses alphabeta pruning to calculate value\n",
        "    # of dropping piece in selected column\n",
        "    def score_move(grid, col, mark, depth):\n",
        "        if debug:\n",
        "            column_time = time.time()\n",
        "        next_grid = drop_piece(grid, col, mark)\n",
        "        score = alphabeta(next_grid, depth-1, -np.Inf, np.Inf, False, mark)      \n",
        "        if debug:\n",
        "            column_time = time.time() - column_time \n",
        "            summary_stats = {\n",
        "                'column': col,\n",
        "                'score': score,\n",
        "                'column_time': round(column_time, 4),\n",
        "                #'time_left': round(time_left, 3),\n",
        "                #'time_elapsed': round(time.time() - START_TIME, 3)\n",
        "            }\n",
        "            print(f'\"summary_stats\":{summary_stats}')\n",
        "        return score\n",
        "    \n",
        "    #########################\n",
        "    # Agent makes selection #\n",
        "    #########################\n",
        "\n",
        "    # Get list of valid moves\n",
        "    valid_moves = [c for c in range(COLUMNS) if obs.board[c] == 0]\n",
        "\n",
        "    # Convert the board to a 2D grid\n",
        "    grid = np.asarray(obs.board).reshape(ROWS, COLUMNS)\n",
        "\n",
        "    # Use the heuristic to assign a score to each possible board in the next step\n",
        "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, N_STEPS) for col in valid_moves]))\n",
        "\n",
        "    # Get a list of columns (moves) that maximize the heuristic\n",
        "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
        "    \n",
        "    #select column in order of preference\n",
        "    for pref in [3,4,2,6,0,5,1]: \n",
        "        if pref in max_cols:\n",
        "            choice = pref\n",
        "            break\n",
        "\n",
        "    if debug:\n",
        "        print(\"Chosen column:\", choice)\n",
        "\n",
        "    return choice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbl8DSDEZD2n"
      },
      "source": [
        "# Test your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDEHDBN09xh8"
      },
      "source": [
        "debug = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Pa3uUqPZD2p"
      },
      "source": [
        "import random\n",
        "env.reset()\n",
        "START_TIME = time.time()\n",
        "# Play against opponent until debug_agent loses\n",
        "test_run = debug # Set debug to True to test\n",
        "debug_agent = lambda x,y: test_agent(x,y, debug=True)\n",
        "\n",
        "#debug_agent = \"my_agent\"\n",
        "from submission import my_agent as opponent\n",
        "#opponent = \"negamax\"\n",
        "#opponent = lambda x,y: test_agent(x,y, START_TIME=START_TIME, debug=False)\n",
        "while test_run:\n",
        "    env.reset()\n",
        "    if random.choice([True, False]):\n",
        "        env.run([debug_agent, opponent])\n",
        "        print(\"Agent order: [test_agent, opponent]\")\n",
        "    else:\n",
        "        env.run([opponent, debug_agent])\n",
        "        print(\"Agent order: [opponent, test_agent]\")\n",
        "\n",
        "    # Don't count ties as losses\n",
        "    if len(env.steps) == 43:\n",
        "        print('tie')\n",
        "        break\n",
        "    elif len(env.steps) % 2 == 1:\n",
        "        print('--- first agent lost ---')\n",
        "        break\n",
        "    else:\n",
        "        print('+++ first agent won +++')\n",
        "        break\n",
        "\n",
        "print('###### Game Over ######')\n",
        "print(f'Game time: {round(time.time()-START_TIME,3)}')\n",
        "#env.render(mode=\"ipython\", width=500, height=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Bqvith-orL"
      },
      "source": [
        "env.render(mode=\"ipython\", width=290, height=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZeFt9ytZD2t"
      },
      "source": [
        "# Debug/Train your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FI-OlTJCZD2v"
      },
      "source": [
        "# Play as first position against random agent.\n",
        "trainer = env.train([None, \"negamax\"])\n",
        "\n",
        "observation = trainer.reset()\n",
        "\n",
        "while debug and not env.done:\n",
        "    my_action = my_agent(observation, env.configuration)\n",
        "    print(\"My Action\", my_action)\n",
        "    observation, reward, done, info = trainer.step(my_action)\n",
        "    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNRi7r05ZD22"
      },
      "source": [
        "# Evaluate your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFQE34lVShAb"
      },
      "source": [
        "from prunerBD import prunerBD as opp2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KNU9JfGXZD23"
      },
      "source": [
        "def mean_reward(rewards):\n",
        "    return sum(r[0] for r in rewards) / float(len(rewards))\n",
        "\n",
        "# Run multiple episodes to estimate its performance.\n",
        "if debug:\n",
        "    print(\"Debug Agent vs Opp Agent:\", mean_reward(evaluate(\"connectx\", [test_agent, \"negamax\"], num_episodes=10)))\n",
        "    print(\"Opp Agent vs Debug Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", test_agent], num_episodes=10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpu8FGFZD26"
      },
      "source": [
        "# Play your Agent\n",
        "Click on any column to place a checker there (\"manually select action\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jtpu9pS7ZD27"
      },
      "source": [
        "# \"None\" represents which agent you'll manually play as (first or second player).\n",
        "env.play([None, my_agent], width=500, height=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsgusz84ZD3A"
      },
      "source": [
        "# Write Submission File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2VO9hB6OZD3B"
      },
      "source": [
        "import inspect\n",
        "import os\n",
        "\n",
        "def write_agent_to_file(function, file):\n",
        "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
        "        f.write(inspect.getsource(function))\n",
        "        print(function, \"written to\", file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zsi0unYcZD3I"
      },
      "source": [
        "submission_file = 'submission.py'\n",
        "write_agent_to_file(my_agent, submission_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rarkIiE8ZD3O"
      },
      "source": [
        "# Validate Submission\n",
        "Play your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n",
        "\n",
        "Why validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yvLra1maZD3Q"
      },
      "source": [
        "# Note: Stdout replacement is a temporary workaround.\n",
        "import sys\n",
        "out = sys.stdout\n",
        "submission = utils.read_file(\"submission.py\")\n",
        "agent = kaggle_env_agent.get_last_callable(submission)\n",
        "sys.stdout = out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hk7AixI3ZD3X"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "env.run([agent, agent])\n",
        "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Otabc-sZD3g"
      },
      "source": [
        "# Submit to Competition\n",
        "\n",
        "1. Save this kernel.\n",
        "2. View the commited version.\n",
        "3. Go to \"Data\" section and find submission.py file.\n",
        "4. Click \"Submit to Competition\"\n",
        "5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."
      ]
    }
  ]
}