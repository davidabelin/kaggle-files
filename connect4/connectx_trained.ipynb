{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "connectx_trained.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yYpQzQvZD1-"
      },
      "source": [
        "Derived from a public notebook by https://www.kaggle.com/mrgeislinger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o4shGZVaZD2K"
      },
      "source": [
        "debug = False"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmBhnSn5r6D"
      },
      "source": [
        "#To DO: Custom Env Policy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHPVSIp4ZD2C"
      },
      "source": [
        "# Install kaggle-environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "dBBtKD-SZD2D"
      },
      "source": [
        "# 1. Enable Internet in the Kernel (Settings side pane)\n",
        "\n",
        "# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n",
        "# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n",
        "\n",
        "# ConnectX environment was defined in v0.1.6\n",
        "!pip install 'kaggle-environments>=0.1.6'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA6lXk_-ZD2R"
      },
      "source": [
        "# Create ConnectX Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qy9Y3xghZD2T"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from kaggle_environments import evaluate, make, utils\n",
        "# Since utils.get_last_callable moved to agent.get_last_callable\n",
        "# See https://github.com/Kaggle/kaggle-environments/blob/e4a5651a3a0775b823fc27fe2c24b55cbd340420/kaggle_environments/agent.py#L37\n",
        "from kaggle_environments import agent as kaggle_env_agent"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "GxDd1F5_ZD2d"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "#env.render()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aerdyYldw-Rq"
      },
      "source": [
        "# Check version of tensorflow\n",
        "!pip install 'tensorflow==1.15.0'\n",
        "import tensorflow as tf\n",
        "#tf.__version__\n",
        "!apt-get update\n",
        "!apt-get install -y cmake libopenmpi-dev python3-dev zlib1g-dev\n",
        "!pip install \"stable-baselines[mpi]==2.9.0\"\n",
        "from gym import spaces\n",
        "from stable_baselines import PPO1 \n",
        "from stable_baselines.common.policies import CnnPolicy\n",
        "\n",
        "model = PPO1.load('/content/given_random.zip', verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1iPJQujZD2i"
      },
      "source": [
        "# Create an Agent\n",
        "\n",
        "To create the submission, an agent function should be fully encapsulated (no external dependencies).  \n",
        "\n",
        "When your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbY_oLgFpvdZ"
      },
      "source": [
        "#@ title Agent to debug\n",
        "def my_agent(obs, config, START_TIME=None, N_STEPS=2, cutoff_time=None, debug=False):\n",
        "\n",
        "    import numpy as np\n",
        "    import random\n",
        "    import time\n",
        "\n",
        "    ########################### Regular pruner ################\n",
        "    # constants (given by game)\n",
        "    ROWS = config.rows\n",
        "    COLUMNS = config.columns\n",
        "    CNCTX = config.inarow\n",
        "    ## coefficients (weights on variable future outcomes)\n",
        "    A = 1     #my twos\n",
        "    B = 100    #my threes\n",
        "    C = 10000   #my fours         \n",
        "    D = -10    #opp-threes\n",
        "    E = -1000   #opp-fours\n",
        "    \n",
        "    # vary lookahead depth according to state of play:\n",
        "    #if debug:\n",
        "        #board = np.reshape(obs.board,(6,7))\n",
        "        #print(\"obs.board:\\n\", board)\n",
        "    if obs.board.count(0) >= ROWS*COLUMNS//2:# or list(obs.board[0]).count(0) >= COLUMNS//2:\n",
        "        N_STEPS =      2\n",
        "    else:\n",
        "        N_STEPS =      3  # deeper search after half the board is filled\n",
        "\n",
        "    cutoff_time_offset=0.2\n",
        "    if START_TIME is None:\n",
        "        START_TIME = time.time()\n",
        "    if cutoff_time is None:\n",
        "        cutoff_time = (config.get('actTimeout', cutoff_time) - cutoff_time_offset)\n",
        "\n",
        "    if debug:\n",
        "        if obs.board.count(1) == 0:\n",
        "            print(f'\"configuration\":{config}')  \n",
        "        print(f'\\n###### Agent Turn {obs.board.count(1):02} ######') \n",
        "        print(f'Using {N_STEPS} step lookahead')\n",
        "\n",
        "    # Gets board at next step if agent drops piece in selected column\n",
        "    def drop_piece(grid, col, mark):\n",
        "        next_grid = grid.copy()\n",
        "        for row in range(ROWS-1, -1, -1):\n",
        "            if next_grid[row][col] == 0:\n",
        "                break\n",
        "        next_grid[row][col] = mark\n",
        "        return next_grid\n",
        "\n",
        "    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n",
        "    def check_window(window, num_discs, piece):\n",
        "        return (window.count(piece) == num_discs and window.count(0) == CNCTX-num_discs)\n",
        "\n",
        "    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n",
        "    def count_windows(grid, num_discs, piece):\n",
        "        num_windows = 0\n",
        "        # horizontal\n",
        "        for row in range(ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[row, col:col+CNCTX])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # vertical\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS):\n",
        "                window = list(grid[row:row+CNCTX, col])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # positive diagonal\n",
        "        for row in range(ROWS-(CNCTX-1)):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row+CNCTX), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        # negative diagonal\n",
        "        for row in range(CNCTX-1, ROWS):\n",
        "            for col in range(COLUMNS-(CNCTX-1)):\n",
        "                window = list(grid[range(row, row-CNCTX, -1), range(col, col+CNCTX)])\n",
        "                if check_window(window, num_discs, piece):\n",
        "                    num_windows += 1\n",
        "        return num_windows\n",
        "\n",
        "    # Helper function for minimax: calculates value of heuristic for grid\n",
        "    def get_score(grid, mark):\n",
        "        num_twos = count_windows(grid, 2, mark) #A\n",
        "        num_threes = count_windows(grid, 3, mark)  #B\n",
        "        num_fours = count_windows(grid, 4, mark)   #C\n",
        "        num_threes_opp = count_windows(grid, 3, mark%2+1) #D\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1)  #E     \n",
        "        score = A*num_twos + B*num_threes + C*num_fours + D*num_threes_opp + E*num_fours_opp\n",
        "        is_terminal = (not num_fours == 0) or (not num_fours_opp == 0) or (list(grid[0, :]).count(0) == 0)\n",
        "        return score, is_terminal\n",
        "\n",
        "    # Minimax implementation was here:\n",
        "    def alphabeta(node, depth, alpha, beta, maximizingPlayer, mark, column_time):\n",
        "        node_score, is_terminal = get_score(node, mark)\n",
        "        # check the time\n",
        "        elapsed_time = time.time() - column_time\n",
        "        if depth == 0 or is_terminal or (elapsed_time >= 1.0):#time_left):\n",
        "             return node_score\n",
        "\n",
        "        valid_moves = [c for c in range(COLUMNS) if node[0][c] == 0]\n",
        "        if maximizingPlayer:\n",
        "            value = -np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark)\n",
        "                value = max(value, alphabeta(child, depth-1, alpha, beta, False, mark, column_time))\n",
        "                alpha = max(alpha, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "        else: #minimizing player\n",
        "            value = np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark%2+1)\n",
        "                value = min(value, alphabeta(child, depth-1, alpha, beta, True, mark, column_time))\n",
        "                beta = min(beta, value)\n",
        "                if alpha >= beta:\n",
        "                    break\n",
        "            return value\n",
        "\n",
        "    # Uses alphabeta pruning to calculate value\n",
        "    # of dropping piece in selected column\n",
        "    def score_move(grid, col, mark, depth):\n",
        "        column_time = time.time()\n",
        "        next_grid = drop_piece(grid, col, mark)\n",
        "        # \"If time is getting close, stop everything!\"\n",
        "        elapsed_time = (column_time - START_TIME ) \n",
        "        time_left = cutoff_time - elapsed_time        #(cutoff_time/config.columns)*(col+1)\n",
        "        if elapsed_time >= cutoff_time:\n",
        "            if debug:\n",
        "                print('\\n*** TIMEOUT ***\\n')\n",
        "            score, _ = get_score(grid, mark)\n",
        "        else:\n",
        "            score = alphabeta(next_grid, depth-1, -np.Inf, np.Inf, False, mark, column_time)\n",
        "        column_time = time.time() - column_time      \n",
        "        if debug:\n",
        "            summary_stats = {\n",
        "                'column': col,\n",
        "                'score': score,\n",
        "                'column_time': round(column_time, 4),\n",
        "                'time_left': round(time_left, 3),\n",
        "                'time_elapsed': round(time.time() - START_TIME, 3)\n",
        "            }\n",
        "            print(f'\"summary_stats\":{summary_stats}')\n",
        "        return score\n",
        "    \n",
        "    #########################\n",
        "    # Agent makes selection #\n",
        "    #########################\n",
        "\n",
        "    # Get list of valid moves\n",
        "    valid_moves = [c for c in range(COLUMNS) if obs.board[c] == 0]\n",
        "\n",
        "    # Convert the board to a 2D grid\n",
        "    grid = np.asarray(obs.board).reshape(ROWS, COLUMNS)\n",
        "\n",
        "    # Use the heuristic to assign a score to each possible board in the next step\n",
        "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, N_STEPS) for col in valid_moves]))\n",
        "\n",
        "    # Get a list of columns (moves) that maximize the heuristic\n",
        "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
        "    \n",
        "    #select column in order of preference\n",
        "    for pref in [3,4,2]: \n",
        "        if pref in max_cols:\n",
        "            choice = pref\n",
        "            break\n",
        "        else:\n",
        "            choice = random.choice(max_cols)\n",
        "    if debug:\n",
        "        print(\"Chosen column:\", choice)\n",
        "\n",
        "    return choice"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Nag2SyZWPcY"
      },
      "source": [
        "def opp(obs, config):\n",
        "    \n",
        "    #Import saved model trained on Agent Heuristic\n",
        "    from stable_baselines import PPO1\n",
        "    trained_model = PPO1.load('/content/given_random.zip', env=env,verbose=0)\n",
        "    \n",
        "    # Use the trained model to select a column\n",
        "    col, _ = trained_model.predict(np.array(obs['board']).reshape(6,7,1))\n",
        "    # Check if selected column is valid\n",
        "    is_valid = (obs['board'][int(col)] == 0)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"Model predicted column:\", col)#, \"Valid =\",is_valid)\n",
        "    \n",
        "    # If not valid, select random move. \n",
        "    if is_valid:\n",
        "        return int(col)\n",
        "    else:\n",
        "        return random.choice([col for col in range(config.columns) if obs.board[int(col)] == 0])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbl8DSDEZD2n"
      },
      "source": [
        "# Test your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDEHDBN09xh8"
      },
      "source": [
        "#from prunerBD import prunerBD as opp\n",
        "debug = True"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Pa3uUqPZD2p",
        "outputId": "0e1e2ac9-7128-4da9-eb9d-6f9cb1f9204c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "env.reset()\n",
        "START_TIME = time.time()\n",
        "# Play against opponent until debug_agent loses\n",
        "test_agent = debug # Set to True to test\n",
        "debug_agent = lambda x,y: my_agent(x,y, START_TIME=START_TIME, debug=True)\n",
        "\n",
        "while test_agent:\n",
        "    env.reset()\n",
        "    env.run([debug_agent, opp])\n",
        "    # Don't count ties as losses\n",
        "    if len(env.steps) == 43:\n",
        "        print('tie')\n",
        "        break\n",
        "    elif len(env.steps) % 2 == 1:\n",
        "        print('--- my_agent lost ---')\n",
        "        break\n",
        "    else:\n",
        "        print('+++ my_agent won +++')\n",
        "        break\n",
        "\n",
        "print('###### Game Over ######')\n",
        "print(f'Game time: {round(time.time()-START_TIME,3)}')\n",
        "#env.render(mode=\"ipython\", width=500, height=450)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"configuration\":{'episodeSteps': 1000, 'agentTimeout': 16, 'actTimeout': 8, 'runTimeout': 1200, 'isProduction': False, 'columns': 7, 'rows': 6, 'inarow': 4, 'timeout': 8}\n",
            "\n",
            "###### Agent Turn 00 ######\n",
            "Using 2 step lookahead\n",
            "\"summary_stats\":{'column': 0, 'score': 0, 'column_time': 0.0214, 'time_left': 7.79, 'time_elapsed': 0.032}\n",
            "\"summary_stats\":{'column': 1, 'score': 0, 'column_time': 0.0167, 'time_left': 7.768, 'time_elapsed': 0.048}\n",
            "\"summary_stats\":{'column': 2, 'score': 0, 'column_time': 0.0165, 'time_left': 7.752, 'time_elapsed': 0.065}\n",
            "\"summary_stats\":{'column': 3, 'score': 0, 'column_time': 0.0184, 'time_left': 7.735, 'time_elapsed': 0.083}\n",
            "\"summary_stats\":{'column': 4, 'score': 0, 'column_time': 0.0165, 'time_left': 7.717, 'time_elapsed': 0.1}\n",
            "\"summary_stats\":{'column': 5, 'score': 0, 'column_time': 0.017, 'time_left': 7.7, 'time_elapsed': 0.117}\n",
            "\"summary_stats\":{'column': 6, 'score': 0, 'column_time': 0.0166, 'time_left': 7.683, 'time_elapsed': 0.134}\n",
            "Chosen column: 3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle_environments/agent.py\", line 159, in act\n",
            "    action = self.agent(*args)\n",
            "  File \"<ipython-input-28-af65f461d599>\", line 5, in opp\n",
            "    trained_model = PPO1.load('/content/given_random.zip', verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/common/base_class.py\", line 886, in load\n",
            "    model.setup_model()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/ppo1/pposgd_simple.py\", line 107, in setup_model\n",
            "    None, reuse=False, **self.policy_kwargs)\n",
            "  File \"<ipython-input-1-0898c7cb94bd>\", line 85, in __init__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py\", line 601, in __init__\n",
            "    feature_extraction=\"cnn\", **_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py\", line 558, in __init__\n",
            "    pi_latent = vf_latent = cnn_extractor(self.processed_obs, **kwargs)\n",
            "  File \"<ipython-input-1-0898c7cb94bd>\", line 77, in modifieError: ['Traceback (most recent call last):\\n', '  File \"/usr/local/lib/python3.6/dist-packages/kaggle_environments/agent.py\", line 159, in act\\n    action = self.agent(*args)\\n', '  File \"<ipython-input-28-af65f461d599>\", line 5, in opp\\n    trained_model = PPO1.load(\\'/content/given_random.zip\\', verbose=0)\\n', '  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/common/base_class.py\", line 886, in load\\n    model.setup_model()\\n', '  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/ppo1/pposgd_simple.py\", line 107, in setup_model\\n    None, reuse=False, **self.policy_kwargs)\\n', '  File \"<ipython-input-1-0898c7cb94bd>\", line 85, in __init__\\n', '  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py\", line 601, in __init__\\n    feature_extraction=\"cnn\", **_kwargs)\\n', '  File \"/usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py\", line 558, in __init__\\n    pi_latent = vf_latent = cnn_extractor(self.processed_obs, **kwargs)\\n', '  File \"<ipython-input-1-0898c7cb94bd>\", line 77, in modified_cnn\\n', 'SystemError: unknown opcode\\n']\n",
            "--- my_agent lost ---\n",
            "###### Game Over ######\n",
            "Game time: 0.158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Bqvith-orL"
      },
      "source": [
        "env.render(mode=\"ipython\", width=290, height=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZeFt9ytZD2t"
      },
      "source": [
        "# Debug/Train your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FI-OlTJCZD2v"
      },
      "source": [
        "# Play as first position against random agent.\n",
        "trainer = env.train([None, \"negamax\"])\n",
        "\n",
        "observation = trainer.reset()\n",
        "\n",
        "while debug and not env.done:\n",
        "    my_action = my_agent(observation, env.configuration)\n",
        "    print(\"My Action\", my_action)\n",
        "    observation, reward, done, info = trainer.step(my_action)\n",
        "    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNRi7r05ZD22"
      },
      "source": [
        "# Evaluate your Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFQE34lVShAb"
      },
      "source": [
        "from prunerBD import prunerBD as opp2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KNU9JfGXZD23"
      },
      "source": [
        "def mean_reward(rewards):\n",
        "    return sum(r[0] for r in rewards) / float(len(rewards))\n",
        "\n",
        "# Run multiple episodes to estimate its performance.\n",
        "if debug:\n",
        "    print(\"Debug Agent vs Opp Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))\n",
        "    print(\"Opp Agent vs Debug Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", my_agent], num_episodes=10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpu8FGFZD26"
      },
      "source": [
        "# Play your Agent\n",
        "Click on any column to place a checker there (\"manually select action\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jtpu9pS7ZD27"
      },
      "source": [
        "# \"None\" represents which agent you'll manually play as (first or second player).\n",
        "env.play([None, my_agent], width=500, height=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsgusz84ZD3A"
      },
      "source": [
        "# Write Submission File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2VO9hB6OZD3B"
      },
      "source": [
        "import inspect\n",
        "import os\n",
        "\n",
        "def write_agent_to_file(function, file):\n",
        "    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
        "        f.write(inspect.getsource(function))\n",
        "        print(function, \"written to\", file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zsi0unYcZD3I"
      },
      "source": [
        "submission_file = 'submission.py'\n",
        "write_agent_to_file(my_agent, submission_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rarkIiE8ZD3O"
      },
      "source": [
        "# Validate Submission\n",
        "Play your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n",
        "\n",
        "Why validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yvLra1maZD3Q"
      },
      "source": [
        "# Note: Stdout replacement is a temporary workaround.\n",
        "import sys\n",
        "out = sys.stdout\n",
        "submission = utils.read_file(\"submission.py\")\n",
        "agent = kaggle_env_agent.get_last_callable(submission)\n",
        "sys.stdout = out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hk7AixI3ZD3X"
      },
      "source": [
        "env = make(\"connectx\", debug=True)\n",
        "env.run([agent, agent])\n",
        "print(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Otabc-sZD3g"
      },
      "source": [
        "# Submit to Competition\n",
        "\n",
        "1. Save this kernel.\n",
        "2. View the commited version.\n",
        "3. Go to \"Data\" section and find submission.py file.\n",
        "4. Click \"Submit to Competition\"\n",
        "5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."
      ]
    }
  ]
}