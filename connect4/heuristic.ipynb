{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "heuristic.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cmrVw5ubSPB"
      },
      "source": [
        "!pip install kaggle_environments\n",
        "import kaggle_environments\n",
        "from kaggle_environments import make, evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zk2BVQCUVB1w"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# How deep to make the game tree: higher values take longer to run!\n",
        "N_STEPS = 2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZGHV-LDiVB11"
      },
      "source": [
        "def get_win_percentages(agent1, agent2, n_rounds=10):\n",
        "    # Use default Connect Four setup\n",
        "    import numpy as np\n",
        "    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n",
        "    # Agent 1 goes first (roughly) half the time          \n",
        "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
        "    # Agent 2 goes first (roughly) half the time      \n",
        "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
        "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n",
        "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n",
        "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
        "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qZcA7WScVB1_"
      },
      "source": [
        "#def my_agent(obs, config):\n",
        "def heuristic(obs, config):\n",
        "\n",
        "    ################################\n",
        "    # Imports and helper functions #\n",
        "    ################################\n",
        "    \n",
        "    import numpy as np\n",
        "    import random\n",
        "    \n",
        "    # How deep to make the game tree: higher values take longer to run!\n",
        "    N_STEPS = 2\n",
        "\n",
        "    # Gets board at next step if agent drops piece in selected column\n",
        "    def drop_piece(grid, col, mark, config):\n",
        "        next_grid = grid.copy()\n",
        "        for row in range(config.rows-1, -1, -1):\n",
        "            if next_grid[row][col] == 0:\n",
        "                break\n",
        "        next_grid[row][col] = mark\n",
        "        return next_grid\n",
        "\n",
        "    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n",
        "    def check_window(window, num_discs, piece, config):\n",
        "        return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n",
        "\n",
        "    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n",
        "    def count_windows(grid, num_discs, piece, config):\n",
        "        num_windows = 0\n",
        "        # horizontal\n",
        "        for row in range(config.rows):\n",
        "            for col in range(config.columns-(config.inarow-1)):\n",
        "                window = list(grid[row, col:col+config.inarow])\n",
        "                if check_window(window, num_discs, piece, config):\n",
        "                    num_windows += 1\n",
        "        # vertical\n",
        "        for row in range(config.rows-(config.inarow-1)):\n",
        "            for col in range(config.columns):\n",
        "                window = list(grid[row:row+config.inarow, col])\n",
        "                if check_window(window, num_discs, piece, config):\n",
        "                    num_windows += 1\n",
        "        # positive diagonal\n",
        "        for row in range(config.rows-(config.inarow-1)):\n",
        "            for col in range(config.columns-(config.inarow-1)):\n",
        "                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
        "                if check_window(window, num_discs, piece, config):\n",
        "                    num_windows += 1\n",
        "        # negative diagonal\n",
        "        for row in range(config.inarow-1, config.rows):\n",
        "            for col in range(config.columns-(config.inarow-1)):\n",
        "                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
        "                if check_window(window, num_discs, piece, config):\n",
        "                    num_windows += 1\n",
        "        return num_windows\n",
        "    \n",
        "    # Helper function for minimax: calculates value of heuristic for grid\n",
        "    A = 2\n",
        "    B = 10\n",
        "    C = -1\n",
        "    D = -10\n",
        "    def get_heuristic(grid, mark, config):\n",
        "        num_threes = count_windows(grid, 3, mark, config) #A\n",
        "        num_fours = count_windows(grid, 4, mark, config)  #B\n",
        "        num_threes_opp = count_windows(grid, 3, mark%2+1, config) #C\n",
        "        num_fours_opp = count_windows(grid, 4, mark%2+1, config)  #D\n",
        "        score = A*num_threes + C*num_threes_opp + D*num_fours_opp + B*num_fours\n",
        "        return score\n",
        "\n",
        "    # Helper function for minimax: checks if agent or opponent has four in a row in the window\n",
        "    def is_terminal_window(window, config):\n",
        "        return window.count(1) == config.inarow or window.count(2) == config.inarow\n",
        "\n",
        "    # Helper function for minimax: checks if game has ended\n",
        "    def is_terminal_node(grid, config):\n",
        "        # Check for draw \n",
        "        if list(grid[0, :]).count(0) == 0:\n",
        "            return True\n",
        "        # Check for win: horizontal, vertical, or diagonal\n",
        "        # horizontal \n",
        "        for row in range(config.rows):\n",
        "            for col in range(config.columns-(config.inarow-1)):\n",
        "                window = list(grid[row, col:col+config.inarow])\n",
        "                if is_terminal_window(window, config):\n",
        "                    return True\n",
        "        # vertical\n",
        "        for row in range(config.rows-(config.inarow-1)):\n",
        "            for col in range(config.columns):\n",
        "                window = list(grid[row:row+config.inarow, col])\n",
        "                if is_terminal_window(window, config):\n",
        "                    return True\n",
        "        # positive diagonal\n",
        "        for row in range(config.rows-(config.inarow-1)):\n",
        "            for col in range(config.columns-(config.inarow-1)):\n",
        "                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
        "                if is_terminal_window(window, config):\n",
        "                    return True\n",
        "        # negative diagonal\n",
        "        for row in range(config.inarow-1, config.rows):\n",
        "            for col in range(config.columns-(config.inarow-1)):\n",
        "                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
        "                if is_terminal_window(window, config):\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    # Minimax implementation\n",
        "    def minimax(node, depth, maximizingPlayer, mark, config):\n",
        "        is_terminal = is_terminal_node(node, config)\n",
        "        valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n",
        "        if depth == 0 or is_terminal:\n",
        "            return get_heuristic(node, mark, config)\n",
        "        if maximizingPlayer:\n",
        "            value = -np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark, config)\n",
        "                value = max(value, minimax(child, depth-1, False, mark, config))\n",
        "            return value\n",
        "        else:\n",
        "            value = np.Inf\n",
        "            for col in valid_moves:\n",
        "                child = drop_piece(node, col, mark%2+1, config)\n",
        "                value = min(value, minimax(child, depth-1, True, mark, config))\n",
        "            return value\n",
        "        \n",
        "    # Uses minimax to calculate value of dropping piece in selected column\n",
        "    def score_move(grid, col, mark, config, nsteps):\n",
        "        next_grid = drop_piece(grid, col, mark, config)\n",
        "        score = minimax(next_grid, nsteps-1, False, mark, config)\n",
        "        return score\n",
        "    \n",
        "    #########################\n",
        "    # Agent makes selection #\n",
        "    #########################\n",
        "    \n",
        "    # Get list of valid moves\n",
        "    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n",
        "    \n",
        "    # Convert the board to a 2D grid\n",
        "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
        "    \n",
        "    # Use the heuristic to assign a score to each possible board in the next step\n",
        "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config, N_STEPS) for col in valid_moves]))\n",
        "    \n",
        "    # Get a list of columns (moves) that maximize the heuristic\n",
        "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
        "    \n",
        "    # Select at random from the maximizing columns\n",
        "    return random.choice(max_cols)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AbV5KWksVB2H",
        "outputId": "6666e96b-2a38-4748-994a-09c14acaf966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_time = time.time()\n",
        "n_rounds=75\n",
        "get_win_percentages(agent1=heuristic, agent2=\"negamax\", n_rounds=n_rounds)\n",
        "print (\"Total time taken: {} seconds (per round: {} seconds)\".format(round(time.time() - start_time, 1), \n",
        "                                                                     round(time.time() - start_time)/n_rounds,3))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agent 1 Win Percentage: 0.87\n",
            "Agent 2 Win Percentage: 0.12\n",
            "Number of Invalid Plays by Agent 1: 0\n",
            "Number of Invalid Plays by Agent 2: 0\n",
            "Total time taken: 705.2 seconds (per round: 9.4 seconds)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kRKH5ymiHsr"
      },
      "source": [
        "#Heuristic vs. Negamax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN9IZ5tgiN-Y"
      },
      "source": [
        "* Heuris dep2: Win Percentage: 0.71\n",
        "* Negamax: Win Percentage: 0.25\n",
        "\n",
        "Total time taken: 270.4 seconds (per round: 2.7 seconds) \n",
        "__________________________________\n",
        "\n",
        "* Heuris dep3: Win Percentage: 0.87\n",
        "* Negamax: Win Percentage: 0.12\n",
        "\n",
        "Total time taken: 705.2 seconds (per round: 9.4 seconds)\n",
        "__________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_xkxQ_UWrmi"
      },
      "source": [
        "#Heuristic vs. Heuristic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2HeFWAmW_hP"
      },
      "source": [
        "* Heuris: (2,10,-1,-10) Win Percentage: 0.61\n",
        "* Tic: (2,4,-1,-8) Win Percentage: 0.39\n",
        "\n",
        "Total time taken: 22.4 seconds (per round: 0.22 seconds)\n",
        "__________________________________\n",
        "\n",
        "* Heuris: (2,10,-1,-10) Win Percentage: 0.47\n",
        "* Tic: (2,10,-1,-5) Win Percentage: 0.53\n",
        "\n",
        "Total time taken: 26.7 seconds (per round: 0.27 seconds)\n",
        "__________________________________\n",
        "\n",
        "* Heuris: dep1, (2,10,-1,-10) Win Percentage: 0.07\n",
        "* Tic: dep2, (2,10,-1,-5) Win Percentage: 0.93\n",
        "\n",
        "Total time taken: 112.4 seconds (per round: 1.12 seconds)\n",
        "__________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLyOOaiwVB2K"
      },
      "source": [
        "#Trial Runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_mnDZ1CVB2L"
      },
      "source": [
        "* My_Agent Win Percentage: 0.41\n",
        "* My_Agent Win Percentage: 0.45\n",
        "* Number of Invalid Plays by My_Agent: 0\n",
        "* Number of Invalid Plays by My_Agent: 0\n",
        "\n",
        "Total time taken: 446.3462007045746 seconds\n",
        "\n",
        "Time taken per round: 4.4634632921218875 seconds\n",
        "__________________________________\n",
        "\n",
        "* Random Win Percentage: 0.04\n",
        "* One_Step Agent Win Percentage: 0.96\n",
        "* Number of Invalid Plays by Random: 0\n",
        "* Number of Invalid Plays by One_Step Agent: 0\n",
        "\n",
        "Total time taken: 16.603688955307007 seconds\n",
        "\n",
        "Time taken per round: 0.16603797674179077 seconds\n",
        "__________________________________\n",
        "\n",
        "* Random Win Percentage: 0.01\n",
        "* My_Agent Win Percentage: 0.99\n",
        "* Number of Invalid Plays by Random: 0\n",
        "* Number of Invalid Plays by My_Agent: 0\n",
        "\n",
        "Total time taken: 142.17096710205078 seconds\n",
        "\n",
        "Time taken per round: 1.4217106986045838 seconds\n",
        "__________________________________\n",
        "\n",
        "* One_Step Agent Win Percentage: 0.56\n",
        "* One_Step Agent Win Percentage: 0.44\n",
        "* Number of Invalid Plays by One_Step Agent: 0\n",
        "* Number of Invalid Plays by One_Step Agent: 0\n",
        "\n",
        "Total time taken: 31.378709077835083 seconds\n",
        "\n",
        "Time taken per round: 0.3137881112098694 seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwmCa77oWLqU"
      },
      "source": [
        "#Write and submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LFuCIo5yVB2O"
      },
      "source": [
        "if False:    \n",
        "    import inspect\n",
        "    import os\n",
        "\n",
        "    def write_agent_to_file(function, file):\n",
        "        with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n",
        "            f.write(inspect.getsource(function))\n",
        "            print(function, \"written to\", file)\n",
        "\n",
        "    write_agent_to_file(my_agent, \"submission.py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwrrRQu_VB1B"
      },
      "source": [
        "### 1) A closer look\n",
        "\n",
        "The heuristic from the tutorial looks at all groups of four adjacent grid locations on the same row, column, or diagonal and assigns points for each occurrence of the following patterns:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.imgur.com/3NvBEGL.png\" width=70%><br/>\n",
        "</center>\n",
        "\n",
        "Is it really necessary to use so many numbers to define the heuristic?  Consider simplifying it, as in the image below.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.imgur.com/grViegG.png\" width=70%><br/>\n",
        "</center>\n",
        "\n",
        "How would each heuristic score the potential moves in the example below (where, in this case, the agent looks only one step ahead)?  Which heuristic would lead to the agent selecting the better move?\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.imgur.com/LWPLy7N.png\" width=100%><br/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9i18-sMVB1u"
      },
      "source": [
        "### 5) Submit to the competition\n",
        "\n",
        "Now, it's time to submit an agent to the competition!  Use the next code cell to define an agent.  (You can see an example of how to write a valid agent in **[this notebook](https://www.kaggle.com/alexisbcook/create-a-connectx-agent)**.)\n",
        "\n",
        "If you decide to use the minimax code from the tutorial, you might like to add [**alpha-beta pruning**](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) to decrease the computation time (i.e., get the minimax algorithm to run much faster!).  In this case, \"alpha\" and \"beta\" to refer to two values that are maintained while the algorithm is running, that help to identify early stopping conditions.  \n",
        "\n",
        "Without alpha-beta pruning, minimax evaluates each leaf node.  With alpha-beta pruning, minimax only evaluates nodes that could provide information that affects the agent's choice of action.  Put another way, it identifies nodes that could not possibly affect the final result and avoids evaluating them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlmU41yWVB2Q"
      },
      "source": [
        "Then, follow these steps to submit your agent to the competition:\n",
        "1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n",
        "2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n",
        "3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
        "4. Click on the **Output** tab on the right of the screen.  Then, click on the blue **Submit** button to submit your results to the leaderboard.\n",
        "\n",
        "You have now successfully submitted to the competition!\n",
        "\n",
        "If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n",
        "\n",
        "\n",
        "Go to **\"My Submissions\"** to view your score and episodes being played.\n",
        "\n",
        "# Keep going\n",
        "\n",
        "Move on to learn how to **[use deep reinforcement learning](https://www.kaggle.com/alexisbcook/deep-reinforcement-learning)** to develop an agent without a heuristic!"
      ]
    }
  ]
}