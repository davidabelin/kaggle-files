{"cells":[{"metadata":{},"cell_type":"markdown","source":"Development by https://www.kaggle.com/mrgeislinger"},{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"debug = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ConnectX Environment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n\nfrom kaggle_environments import evaluate, make, utils\n# Since utils.get_last_callable moved to agent.get_last_callable\n# See https://github.com/Kaggle/kaggle-environments/blob/e4a5651a3a0775b823fc27fe2c24b55cbd340420/kaggle_environments/agent.py#L37\nfrom kaggle_environments import agent as kaggle_env_agent","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"env = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This agent one-step lookahead chooses a non-empty column\n# kaggle.com/alexisbcook/one-step-lookahead\ndef my_agent(observation, configuration, N_STEPS=2, cutoff_time=None, cutoff_time_offset=0.6, debug=True):\n    '''\n    '''\n    import numpy as np\n    import random\n    import time\n    \n    # Modify to 3 step lookead after about half the board is filled\n    if observation.board.count(1) >= 11:\n        N_STEPS=3\n    \n    # Parameters for keeping track of time while searching deeply\n    START_TIME = time.time()\n    \n    # Use the configurations action timeout as basis the cutoff time\n    if cutoff_time is None:\n        cutoff_time = (configuration.get('actTimeout',cutoff_time) - cutoff_time_offset)\n        \n    if debug:\n        print(f'###### Turn {observation.board.count(1):02} ######') \n        # Just to check for debugging (first 2 turns)\n        if observation.board.count(1) <= 1:\n            print(f'\"configuration\":{configuration}')   \n        print('Cutoff Time:',cutoff_time)\n        print(f'Using {N_STEPS} step lookahead')\n\n    # Helper function for score_move: gets board at next step if agent drops piece in selected column\n    def drop_piece(grid, col, mark, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = mark\n        return next_grid\n\n    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n    def check_window(window, num_discs, piece, config):\n        return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n\n    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n    def count_windows(grid, num_discs, piece, config):\n        num_windows = 0\n        # horizontal\n        for row in range(config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[row, col:col+config.inarow])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # vertical\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns):\n                window = list(grid[row:row+config.inarow, col])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # positive diagonal\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # negative diagonal\n        for row in range(config.inarow-1, config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        return num_windows\n\n    # Helper function for score_move: gets board at next step if agent drops piece in selected column\n    def drop_piece(grid, col, mark, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = mark\n        return next_grid\n\n    # Helper function for minimax: calculates value of heuristic for grid\n    def get_heuristic(grid, mark, config):\n        num_twos = count_windows(grid, 2, mark, config)\n        num_threes = count_windows(grid, 3, mark, config)\n        num_fours = count_windows(grid, 4, mark, config)\n        num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n        num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n        # Only consider fours & threes\n        score = 1e6*num_fours + 1e0*num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp \n        return score\n\n    # Uses minimax to calculate value of dropping piece in selected column\n    def score_move(grid, col, mark, config, nsteps):\n        next_grid = drop_piece(grid, col, mark, config)\n        # If time is getting close, stop everything!\n        time_to_search_col = (cutoff_time/config.columns)*(col+1)\n        if (time.time() - START_TIME ) >= time_to_search_col:\n            print('timeout!!')\n            score = get_heuristic(grid, mark, config)\n        else:\n            minimax_out = minimax(next_grid, nsteps-1, False, mark, config, time_to_search_col)\n            score = minimax_out\n        if debug:\n            summary_stats = {\n                'column': col,\n                'score': score,\n                'nsteps_to_take': nsteps,\n                'time_to_search_col': time_to_search_col,\n                'time_elapsed':time.time() - START_TIME\n            }\n            print(f'\"summary_stats\":{summary_stats}')\n        return score\n\n    # Helper function for minimax: checks if agent or opponent has four in a row in the window\n    def is_terminal_window(window, config):\n        return window.count(1) == config.inarow or window.count(2) == config.inarow\n\n    # Helper function for minimax: checks if game has ended\n    def is_terminal_node(grid, config):\n        # Check for draw \n        if list(grid[0, :]).count(0) == 0:\n            return True\n        # Check for win: horizontal, vertical, or diagonal\n        # horizontal \n        for row in range(config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[row, col:col+config.inarow])\n                if is_terminal_window(window, config):\n                    return True\n        # vertical\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns):\n                window = list(grid[row:row+config.inarow, col])\n                if is_terminal_window(window, config):\n                    return True\n        # positive diagonal\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n                if is_terminal_window(window, config):\n                    return True\n        # negative diagonal\n        for row in range(config.inarow-1, config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n                if is_terminal_window(window, config):\n                    return True\n        return False\n\n    # Minimax implementation\n    def minimax(node, depth, maximizingPlayer, mark, config, timeout_elapsed):\n        is_terminal = is_terminal_node(node, config)\n        valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n        # Check if we've reached the cutoff time\n        elapsed_time = time.time() - START_TIME\n        if (elapsed_time >= timeout_elapsed):\n            # If time runs out, just look for the current heuristic at this depth\n            return get_heuristic(node, mark, config)\n        elif depth == 0 or is_terminal:\n            return get_heuristic(node, mark, config)\n        if maximizingPlayer:\n            value = -np.Inf\n            for col in valid_moves:\n                child = drop_piece(node, col, mark, config)\n                # Get the deepest it went\n                minimax_out = minimax(child, depth-1, False, mark, config, timeout_elapsed)\n                value = max(value, minimax_out)\n        else:\n            value = np.Inf\n            for col in valid_moves:\n                child = drop_piece(node, col, mark%2+1, config)\n                minimax_out = minimax(child, depth-1, True, mark, config, timeout_elapsed)\n                value = min(value, minimax_out)\n        return value\n\n    \n    # Get list of valid moves\n    valid_moves = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    # Convert the board to a 2D grid\n    grid = np.asarray(observation.board).reshape(configuration.rows, configuration.columns)\n    # Use the heuristic to assign a score to each possible board in the next step\n    scores = dict(zip(valid_moves, [score_move(grid, col, observation.mark, configuration, N_STEPS) for col in valid_moves]))\n    # Get a list of columns (moves) that maximize the heuristic\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n    # Select at random from the maximizing columns    \n    chosen_col = random.choice(max_cols)\n    \n    # Try to pick the middle column if it is maximal choice\n    mid_col = configuration.columns // 2\n    if mid_col in max_cols:\n        chosen_col = mid_col\n    # Otherwise choose the off-by-one from the center column\n    elif (mid_col + 1) in max_cols:\n        chosen_col = mid_col+1\n        if (mid_col - 1) in max_cols:\n            chosen_col = random.choice([mid_col-1,mid_col+1])\n    elif (mid_col - 1) in max_cols:\n            chosen_col = mid_col-1\n    \n    if debug:\n        print(f'Total time: {time.time()- START_TIME}')\n    \n    return chosen_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n# Play against \"negamax\" agent until my agent loses\ntest_agent = debug # Set to True to test \ndebug_agent = lambda x,y: my_agent(x,y, debug=True)\nwhile test_agent:\n    env.reset()\n    env.run([debug_agent, 'negamax'])\n    # Don't count ties as losses\n    if len(env.steps) == 43:\n        print('tie')\n    elif len(env.steps) % 2 == 1:\n        print('lost')\n        break\n    else:\n        print('won')\n    print('=======')\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Debug/Train your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"negamax\"])\n\nobservation = trainer.reset()\n\nwhile debug and not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) / float(len(rewards))\n\n# Run multiple episodes to estimate its performance.\nif debug:\n    print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\n    print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Play your Agent\nClick on any column to place a checker there (\"manually select action\")."},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([None, my_agent], width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Submission File\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = 'submission.py'\nwrite_agent_to_file(my_agent, submission_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"/kaggle/working/submission.py\")\nagent = kaggle_env_agent.get_last_callable(submission)\nsys.stdout = out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Competition\n\n1. Save this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}